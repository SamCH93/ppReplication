%% Template for a scientific paper by Samuel Pawel
%% Last modification: 17. December 2020
\documentclass[a4paper, 11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphics}
\usepackage[dvipsnames]{xcolor}
\usepackage{amsmath, amssymb}
\usepackage{doi} % automatic doi-links
\usepackage[round]{natbib} % bibliography
\usepackage{booktabs} % nicer tables
\usepackage[title]{appendix} % better appendices
\usepackage{nameref} % reference appendices with names
\usepackage[onehalfspacing]{setspace} % more space
\usepackage[labelfont=bf,font=small]{caption} % smaller captions

%% margins
\usepackage{geometry}
\geometry{
  a4paper,
  total={170mm,257mm},
  left=25mm,
  right=25mm,
  top=20mm,
  bottom=20mm,
}

%% title, authors, affiliations, mail
\newcommand\longtitle{Power Priors for Replication Studies}
\newcommand\shorttitle{Power Priors for Replication Studies} % if longtitle too long, change here
\newcommand\subtitle{}
\newcommand\longauthors{Samuel Pawel\textsuperscript{$\star$}, Frederik Aust\textsuperscript{$\dagger$}, Leonhard Held\textsuperscript{$\star$}, Eric-Jan Wagenmakers\textsuperscript{$\dagger$}}
\newcommand\shortauthors{S. Pawel, F. Aust, L. Held, E.-J. Wagenmakers} % if longauthors too long, change here
\newcommand\affiliation{
  $\star$ Department of Biostatistics, University of Zurich \\
  $\dagger$ Department of Psychological Methods, University of Amsterdam
}
\newcommand\mail{samuel.pawel@uzh.ch}
\title{
  \vspace{-3em}
  \textbf{\longtitle} \\
  \subtitle
}
\author{
  \textbf{\longauthors} \\
  \affiliation \\
  E-mail: \href{mailto:\mail}{\mail}
}
\date{July 29, 2022} %don't forget to hard-code date when submitting to arXiv!

%% hyperref options
\usepackage{hyperref}
\hypersetup{
  unicode=true,
  bookmarksopen=true,
  breaklinks=true,
  pdftitle={\shorttitle},
  pdfauthor={\shortauthors},
  pdfsubject={},
  pdfkeywords={},
  colorlinks=true,
  linkcolor=blue,
  anchorcolor=black,
  citecolor=blue,
  urlcolor=black,
}

%% Headers and footers
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{\shorttitle}
\rhead{\shortauthors}

%% custom commands
\input{defs.tex}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
\maketitle

%% Disclaimer that a preprint
\vspace{-3em}
\begin{center}
  {\color{red}This is a preprint which has not yet been peer reviewed.}
\end{center}

<< "main-setup", include = FALSE >>=
## knitr options
library(knitr)
opts_chunk$set(fig.height = 4,
               echo = FALSE,
               warning = FALSE,
               message = FALSE,
               cache = FALSE,
               eval = TRUE)

## should sessionInfo be printed at the end?
Reproducibility <- TRUE

## Packages
library(ppRep) # package containing power prior routines
library(ggplot2) # plotting
library(colorspace) # colors
library(xtable) # LaTeX tables
library(dplyr) # easier data manipulation
library(hypergeo) # confluent hypergeometric function
library(ReplicationSuccess) # for data set
library(gridExtra) # combining plots
@

%% Abstract
%% -----------------------------------------------------------------------------
\begin{center}
  \begin{minipage}{13cm} {\small
      \rule{\textwidth}{0.5pt} \\
      {\centering \textbf{Abstract} \\
        The ongoing replication crisis in science has increased interest in the
        methodology of replication studies. We propose a novel Bayesian analysis
        approach using power priors: The likelihood of the original study's data
        is raised to the power of $\alpha$, and then used as the prior
        distribution in the analysis of the replication data. Posterior
        distribution and Bayes factor hypothesis tests related to the power
        parameter $\alpha$ quantify the degree of compatibility between the
        original and replication study. Inferences for other parameters, such as
        effect sizes, dynamically borrow information from the original study.
        The degree of borrowing depends on the conflict between the two studies.
        The practical value of the approach is illustrated on data from three
        replication studies, and the connection to hierarchical modeling
        approaches explored. We generalize the known connection between normal
        power priors and normal hierarchical models for fixed parameters and
        show that normal power prior inferences with a beta prior on the power
        parameter $\alpha$ align with normal hierarchical model inferences using
        a generalized beta prior on the relative heterogeneity variance $I^2$.
        The connection illustrates that power prior modeling is unnatural from
        the perspective of hierarchical modeling since it corresponds to
        specifying priors on a relative rather than an absolute heterogeneity
        scale.
      } \\
      \rule{\textwidth}{0.5pt} \emph{Keywords}: Bayes factor, Bayesian
      hypothesis testing, Bayesian parameter estimation, hierarchical models,
      historical data}
  \end{minipage}
\end{center}


\section{Introduction}

Power priors form a class of informative prior distributions that allow data
analysts to incorporate historical data into a Bayesian analysis
\citep{Ibrahim2015}. The most basic version of the power prior is obtained by
updating an initial prior distribution with the likelihood of the historical
data raised to the power of $\alpha$, where $\alpha$ is usually restricted to
the range from zero (i.e., complete discounting) to one (i.e., complete
pooling). As such, the power parameter $\alpha$ specifies the degree to which
historical data are discounted, thereby providing a quantitative compromise
between the extreme positions of completely ignoring and fully trusting the
historical data.

One domain where historical data are per definition available is the analysis of
replication studies. One pertinent question in this domain is the extent to
which a replication study has successfully replicated the result of an original
study. Many methods have been proposed to address this question \citep[among
others]{Bayarri2002, Verhagen2014, Johnson2016, Etz2016, vanAert2017, Ly2018,
  Hedges2019, Mathur2020, Held2020, Pawel2020, Pawel2020b, Held2021}. Here we
propose a new and conceptually straightforward approach, namely to construct a
power prior for the data from the original study, and to use that prior to draw
inferences from the data of the replication study.

Below we first show how power priors can be constructed from data of an original
study under a meta-analytic framework (Section~\ref{sec:power-prior}). We then
shown how the power prior can be used for parameter estimation
(Section~\ref{sec:parameter-estimation}), Bayes factor hypothesis testing
(Section~\ref{sec:hypothesis-testing}), and for the design of new replication
studies (Section~\ref{sec:design}). Throughout, the methodology is illustrated
by application to data from three replication studies which were part of a
large-scale replication project \citep{Protzko2020}. In
Section~\ref{sec:hierarch}, we explore the connection to the alternative
hierarchical modeling approach for incorporating the original data
\citep{Bayarri2002, Bayarri2002b, Pawel2020}, which has been previously used for
evidence synthesis and compatibility assessment in replication settings. In
doing so, we identify explicit conditions under which posterior distributions
and tests can be reverse-engineered from one framework to the other.
Essentially, power prior inferences using the commonly assigned beta prior on
the power parameter $\alpha$ align with normal hierarchical model inferences if
either a generalized F prior is assigned to the between-study heterogeneity
variance $\tau^2$ which scales with the variance of the original data, or if a
generalized beta prior is assigned to the relative heterogeneity $I^2$. This
perspective also explains the observed difficulty of making conclusive
inferences about the power parameter $\alpha$ as it is difficult to make
inferences about a variance from two observations alone, and also because the
commonly assigned beta prior on $\alpha$ is entangled with the variance from the
data.


\section{Power prior modeling of replication studies}
\label{sec:power-prior}

Let $\theta$ denote an unknown effect size and $\that_{i}$ an estimate thereof
obtained from study $i \in \{o, r\}$ where the subscript indicates ``original''
and ``replication'', respectively. Assume that the likelihood of the effect
estimates can be approximated by a normal distribution
\begin{align*}
  \that_{i} \given \theta \sim \Nor(\theta, \sigma^{2}_{i})
\end{align*}
with $\sigma_{i}$ the (assumed to be known) standard error of the effect
estimate $\that_{i}$. The effect size may be adjusted for confounding variables,
and depending on the outcome variable, a transformation may be required for the
normal approximation to be accurate (\eg{} a log-transformation for an odds
ratio effect size). This is the same framework that is typically used in
meta-analysis, and it is applicable to many types of data and effect sizes
\citep[chapter 2.4]{Spiegelhalter2004}. There are, of course, situations where
the approximation is inadequate and modified distributional assumptions are
required (\eg{} for data from studies with small sample sizes and/or extreme
effect sizes).

The goal is now to construct a power prior for $\theta$ based on the data from
the original study. Updating of an (improper) flat initial prior
$f(\theta) \propto 1$ by the likelihood of the original data raised to a (fixed)
power parameter $\alpha$ leads to the normalized power prior
\begin{align}
  \theta \given \that_{o}, \alpha
  \sim \Nor\left(\that_{o}, \sigma^{2}_{o}/\alpha \right)
  \label{eq:pp}
\end{align}
as first proposed by \citet{Duan2005}, see also \citet{Neuenschwander2009}.
There are different ways to specify $\alpha$. The simplest approach fixes
$\alpha$ to an \emph{a priori} reasonable value, possibly informed by background
knowledge about the similarity of the two studies. Another option is to use the
empirical Bayes estimate \citep{Gravestock2017}, that is, the value of $\alpha$
that maximizes the likelihood of the replication data marginalized over the
power prior.
% \begin{align*}
%   \hat{\alpha}_{\text{EB}}
%   = \begin{cases}
%   1 & \text{if} ~ (\that_r - \that_o)^2 - \sigma^2_r \leq 0 \\
%   \min\left[1, \sigma^2_o \, \big/ \left\{(\that_r - \that_o)^2 - \sigma^2_r\right\}\right]
%   & \text{else}.
%   \end{cases}
% \end{align*}
Finally, it is also possible to specify a prior distribution for $\alpha$, the
most common choice being a beta distribution $\alpha \given x, y \sim \Be(x, y)$
for a normalized power prior conditional on $\alpha$ as in~\eqref{eq:pp}. This
approach leads to a joint prior for the effect size $\theta$ and power parameter
$\alpha$ with density
\begin{align}
    f(\theta, \alpha \given \that_o, x, y)
    = \Nor(\theta \given \that_o, \sigma^2_o/\alpha) \, \Be(\alpha \given x, y)
    \label{eq:ppjoint}
\end{align}
where $\Nor(\cdot \given m, v)$ is the normal density function with mean $m$ and
variance $v$, and $\Be( \cdot \given x, y)$ is the beta density with parameters
$x$ and $y$. The uniform distribution ($x = 1$, $y = 1$) is often recommended as
the default choice \citep{Ibrahim2015}. We note that $\alpha$ does not have to
be restricted to the unit interval but could also be treated as a relative
precision parameter \citep{Held2017}. We will, however, not consider such an
approach since power parameters $\alpha > 1$ lead to priors with more
information than what was actually supplied by the original study.

\subsection{Parameter estimation}
\label{sec:parameter-estimation}

Updating the prior~\eqref{eq:ppjoint} with the likelihood of the replication
data leads to the posterior distribution
\begin{align}
  f(\alpha, \theta \given \that_{r}, \that_{o}, x, y)
  =& \frac{\Nor(\that_{r}\given \theta, \sigma^{2}_{r}) \,
     \Nor(\theta\given \that_{o}, \sigma^{2}_{o}/\alpha) \, \Be(\alpha\given x, y)}{
     f(\that_{r} \given \that_{o}, x, y)}.
     \label{eq:posterior}
%   \\ \propto& \exp\left[-\frac{1}{2} \left\{
%           \left(\frac{1}{\sigma^{2}_{r}} + \frac{\alpha}{\sigma^{2}_{o}}\right)
%           \left(\theta - \frac{\that_{r}/\sigma^{2}_{r} + (\that_{r}\, \alpha) / \sigma^{2}_{o}}{
%           1/\sigma^{2}_{r} + \alpha/\sigma^{2}_{o}}\right)^{2} +
%           \frac{(\that_{o} - \that_{r})^{2}}{\sigma^{2}_{o}/\alpha + \sigma^{2}_{r}}
%           \right\}\right]  \nonumber \\
%   & \, \alpha^{x - 1/2} \, (1 - \alpha)^{y - 1} \nonumber
\end{align}
The normalizing constant
\begin{align}
  f(\that_{r} \given \that_{o}, x, y)
%   &= \int_{0}^{1} \int_{-\infty}^{\infty} \Nor(\that_{r}\given \theta, \sigma^{2}_{r}) \,
%   \Nor(\theta\given \that_{o}, \sigma^{2}_{o}/\alpha) \, \Be(\alpha\given x, y) \,
%   \text{d}\theta \, \text{d}\alpha \nonumber \\
  &= \int_{0}^{1}  \Nor(\that_{r}\given \that_{o},  \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha)
  \, \Be(\alpha\given x, y) \, \text{d}\alpha
  \label{eq:normConst}
\end{align}
is generally not available in closed form but requires numerical integration
with respect to $\alpha$. If inference concerns only one parameter, a marginal
posterior distribution for either $\alpha$ or $\theta$ can be obtained by
integrating out the respective nuisance parameter from~\eqref{eq:posterior}. In
the case of the power parameter $\alpha$, this leads to
\begin{align}
  f(\alpha \given \that_{r}, \that_{o}, x, y)
  =& \frac{\Nor(\that_{r}\given \that_{o}, \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha) \,
     \Be(\alpha\given x, y)}{f(\that_{r} \given \that_{o}, x, y)}
     \label{eq:margalpha}
\end{align}
whereas for the effect size $\theta$, this gives
\begin{align*}
  f(\theta \given \that_{r}, \that_{o}, x, y)
%   &= \frac{\Nor(\that_{r}\given \theta, \sigma^{2}_{r}) \, \int_{0}^{1}
%      \Nor(\theta\given \that_{o}, \sigma^{2}_{o}/\alpha) \, \Be(\alpha\given x, y)
%      \, \text{d}\alpha}{f(\that_{r} \given \that_{o}, x, y)} \\
     &= \frac{\Nor(\that_{r}\given \theta, \sigma^{2}_{r})
     \, \mbox{B}(x + 1/2, y)}{
     f(\that_{r} \given \that_{o}, x, y) \, \sqrt{2\pi\sigma_o^2}
     \, \mbox{B}(x, y)}
     \, M\bigg\{x + 1/2, x + y + 1/2, -\frac{(\that_o - \theta)^2}{2\sigma^2_o}\bigg\}
\end{align*}
with
$\mbox{B}(z, w) = \int_0^1 t^{z-1}(1 - t)^{w-1} \,\text{d}t = \{\Gamma(z)\Gamma(w)\}/\Gamma(z + w)$
the beta function and
$M(a, b, z) = \{\int_0^1 \exp(zt) t^{a-1}(1-t)^{b-a-1} \,\text{d}t\}/\mbox{B}(b - a, a)$
the confluent hypergeometric function \citep[chapters 6 and 13]{Abramowitz1964}.

<< "data" >>=
## Protzko data set is now included in ReplicationSuccess package
data(protzko2020, package = "ReplicationSuccess")
ex <- "Labels"
dat <- subset(protzko2020, experiment == ex)

## Original data
to <- dat$smd[dat$type == "original"]
## add a tiny amount so that correctly rounded (as 0.205 is rounded down to 2.0 ....)
to <- to + .Machine$double.eps
no <- dat$n[dat$type == "original"]

## Replication data
tr <- dat$smd[dat$type == "external-replication"]
## add a tiny amount so that correctly rounded (as 0.205 is rounded down to 2.0 ....)
tr[3] <- tr[3] + .Machine$double.eps
so <- dat$se[dat$type == "original"]
sr <- dat$se[dat$type == "external-replication"]
nr <- dat$n[dat$type == "external-replication"]
rnumber <- c(1, 3, 2)

## Uniform prior for alpha
x <- 1
y <- 1
@

\subsubsection{Example ``\Sexpr{ex}''}

We now illustrate the methodology on data from the large-scale replication
project by \citet{Protzko2020}. The project featured an experiment called
``Labels'' for which the original study reported the following conclusion:
``When a researcher uses a label to describe people who hold a certain opinion,
he or she is interpreted as disagreeing with those attributes when a negative
label is used and agreeing with those attributes when a positive label is used''
\citep[p. 17]{Protzko2020}. This conclusion was based on a standardized mean
difference effect estimate $\that_{o} = \Sexpr{round(to, 2)}$ and standard error
$\sigma_{o} = \Sexpr{round(so, 2)}$ obtained from $\Sexpr{round(no, 1)}$
participants. Subsequently, four replication studies were conducted, three of
them by a different laboratory than the original one, and all employing large
sample sizes. Since the same original study was replicated by three independent
laboratories, this is an instance of a ``multisite'' replication design
\citep{Mathur2020}. While in principle it would be possible to analyze all of
these studies jointly, we will show separate analyses for each pair of original
and replication study as it reflects the typical situation of only one
replication study being conducted per original study.
Section~\ref{sec:discussion} discusses possible extensions of the power prior
approach for joint analyses in multisite designs.
\begin{figure}[!htb]
<< "figure-posterior-distribution", fig.height = 6 >>=
## Parameter grid to compute posterior density for
nalpha <- 200
ntheta <- 200
alphaseq <- seq(0, 1, length.out = nalpha)
thetaseq <- seq(0, 0.6, length.out = ntheta)
parGrid <- expand.grid(alpha = alphaseq, theta = thetaseq)
m <- 0
v <- Inf

## Joint posterior
jointplotDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    pDens <- postPP(theta = parGrid$theta, alpha = parGrid$alpha, tr = tr[i],
                    sr = sr[i], to = to, so = so, x = x, y = y, m = m, v = v)
    parGrid$density <- pDens
    parGrid$tr <- tr[i]
    parGrid$sr <- sr[i]
    parGrid$rnumber <- rnumber[i]
    return(parGrid)
}))
jointplotDF$trFormat <- paste0("{hat(theta)[italic('r')*", jointplotDF$rnumber,
                               "] == ", round(jointplotDF$tr, 2),
                               "}*',' ~ sigma[italic('r')*", jointplotDF$rnumber,
                               "] == ", round(jointplotDF$sr, 2))

## Plot of joint posterior
plotTop <- ggplot(data = jointplotDF, aes(x = theta, y = alpha, fill = density)) +
    facet_wrap(~ trFormat,
               labeller = label_parsed) +
    geom_raster() +
    geom_contour(aes(z = density), breaks = seq(0, 30, 5), alpha = 0.25, col = 1,
                 size = 0.3) +
    scale_fill_continuous_sequential(palette = "Blues 3", rev = TRUE) +
    labs(x = bquote("Effect size" ~ theta),
         y = bquote("Power parameter" ~ alpha),
         fill = "Posterior \ndensity") +
    guides(fill = guide_colorbar(barheight = 10, barwidth = 0.5)) +
    theme_minimal() +
    theme(panel.grid.minor = element_blank())

## Marginal posteriors
alphaplotDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    pDens <- postPPalpha(alpha = alphaseq, tr = tr[i], sr = sr[i], to = to,
                         so = so, x = x, y = y, m = m, v = v)
    out <- data.frame(x = alphaseq, density = pDens, rnumber = rnumber[i],
                      parameter = "'Power parameter' ~ alpha", tr = tr[i], sr = sr[i])
    return(out)
}))
thetaplotDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    pDens <- postPPtheta(theta = thetaseq, tr = tr[i], sr = sr[i], to = to,
                         so = so, x = x, y = y, m = m, v = v)
    out <- data.frame(x = thetaseq, density = pDens, rnumber = rnumber[i],
                      parameter = "'Effect size' ~ theta", tr = tr[i], sr = sr[i])
    return(out)
}))
margplotDF <- rbind(alphaplotDF, thetaplotDF)
margplotDF$trFormat <- paste0("{hat(theta)[italic('r')*", margplotDF$rnumber,
                              "] == ", round(margplotDF$tr, 2),
                              "}*',' ~ sigma[italic('r')*", margplotDF$rnumber,
                              "] == ", round(margplotDF$sr, 2))

## Posterior of effect size without using original data
thetaplotDF2 <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    pDens <- dnorm(x = thetaseq, mean = tr[i], sd = sr[i])
    out <- data.frame(x = thetaseq, density = pDens, rnumber = rnumber[i],
                      parameter = "'Effect size' ~ theta", tr = tr[i], sr = sr[i])
    return(out)
}))
thetaplotDF2$trFormat <- paste0("{hat(theta)[italic('r')*", thetaplotDF2$rnumber,
                                "] == ", round(thetaplotDF2$tr, 2),
                                "}*',' ~ sigma[italic('r')*",
                                thetaplotDF2$rnumber, "] == ",
                                round(thetaplotDF2$sr, 2))

## Limitting density for perfectly agreeing effect estimates with c = so^2/sr^2 -> infty
alphaLimitDF <- data.frame(x = alphaseq,
                           density = dbeta(x = alphaseq, x + 0.5, y),
                           parameter = "'Power parameter' ~ alpha")

## colorblind friendly scale
ncat <- length(unique(margplotDF$trFormat))
colblind <- palette.colors(n = ncat + 1, palette = "Okabe-Ito")[2:(ncat + 1)]
names(colblind) <- unique(margplotDF$trFormat)
colblind <- colblind[order(names(colblind))]

## Plot of marginal posteriors
plotBot <- ggplot(data = margplotDF, aes(x = x, y = density, color = trFormat)) +
    facet_wrap(~ parameter, scales = "free", labeller = label_parsed,
               strip.position = "bottom") +
    geom_line(data = thetaplotDF2, lty = 2, alpha = 0.5, size = 0.7) +
    geom_line(alpha = 0.9, size = 0.7) +
    geom_line(data = alphaLimitDF, aes(x = x, y = density), col = 1, lty = 3, alpha = 0.5) +
    theme_bw() +
    labs(x = NULL, y = "Marginal posterior density", color = "") +
    scale_color_manual(values = colblind, labels = scales::parse_format()) +
    ## scale_color_discrete_qualitative(palette = "Dark 3",
    ##                                  labels = scales::parse_format()) +
    theme(legend.position = "top", panel.grid.minor = element_blank(),
          strip.background.x = element_blank(), strip.placement = "outside",
          legend.text.align = 0, strip.text.x = element_text(size = 11))

## Combine all plots
grid.arrange(plotTop, plotBot, ncol = 1)
## ggpubr::ggarrange(plotTop, plotBot, ncol = 1, heights = c(0.5, 0.5))
@
\caption{Analysis of three replication studies of the ``Labels'' experiment from
  \citet{Protzko2020}. Shown are joint (top) and marginal (bottom) posterior
  distributions of effect size $\theta$ and power parameter $\alpha$. A power
  prior for the effect size $\theta$ is constructed from the original effect
  estimate $\that_{o} = \Sexpr{round(to, 2)}$ (with standard error
  $\sigma_{o} = \Sexpr{round(so, 2)}$) and an initial flat prior
  $f(\theta) \propto 1$. The power parameter $\alpha$ is assigned a uniform
  $\Be(\Sexpr{round(x, 2)}, \Sexpr{round(y, 2)})$ prior distribution. The dashed
  lines depict the posterior density for the effect size $\theta$ when the
  replication data are analysed in isolation without incorporation of the
  original data. The dotted line represents the limiting posterior density of
  the power parameter $\alpha$ for perfectly agreeing original and replication
  studies.}
\label{fig:post2d}
\end{figure}

Figure~\ref{fig:post2d} shows joint and marginal posterior distributions for
effect size $\theta$ and power parameter $\alpha$ based on the results of the
three external replication studies. The first replication found an effect
estimate which was smaller than the original one
($\that_{r1} = \Sexpr{round(tr[1], 2)}$), whereas the other two replications
found effect estimates that were either identical
($\that_{r2} = \Sexpr{round(tr[3], 2)}$) or larger
($\that_{r3} = \Sexpr{round(tr[2], 2)}$) than that reported in the original
study. This is reflected in the marginal posterior distributions of the power
parameter $\alpha$, shown in the bottom right panel of Figure~\ref{fig:post2d}.
That is, the marginal distribution of the first replication (yellow) is slightly
peaked around $\alpha = 0.2$ suggesting some incompatibility with the original
study. In contrast, the second replication shows a marginal distribution (green)
which is monotonically increasing so that the value $\alpha = 1$ receives the
highest support, thereby indicating compatibility of the two studies. Finally,
the marginal distribution of the third replication (blue) is sharply peaked
around $\alpha = 0.05$ indicating strong conflict between this replication and
the original study. The sharply peaked posterior is in stark contrast to the
relatively diffuse posteriors of the first and second replications which hardly
changed from the uniform prior. This is consistent with the asymptotic behavior
of normalized power priors identified in \citet{Pawel2022c}; In case of data
incompatibility, normalized power priors with beta prior assigned to $\alpha$
permit arbitrarily peaked posteriors for small values of $\alpha$, whereas in
case of data compatibility there is a limiting posterior for $\alpha$ that
hardly differs from the prior. The limiting posterior is in this case a
$\Be(3/2, 1)$ distribution, whose density is indicated by the dotted line. One
can see, that the (green) posterior from the second replication is relatively
close to the limiting posterior, despite its finite sample size.


The bottom left panel of Figure~\ref{fig:post2d} shows the marginal posterior
distribution of the effect size $\theta$. Shown is also the posterior
distribution of $\theta$ when the replication data are analyzed in isolation
(dashed line), to see the information gain from incorporating the original data
via a power prior. The degree of compatibility with the replication study
influences how much information is borrowed from the original study. For
instance, the (green) marginal posterior density based on the most compatible
replication ($\that_{r2} = \Sexpr{round(tr[3], 2)}$) is the most concentrated
among the three replications, despite the standard error being the largest
(\ie{} $\sigma_{r2} = \Sexpr{round(sr[3], 2)}$). In contrast, the (blue)
marginal posterior of the most conflicting estimate (\ie{}
$\that_{r3} = \Sexpr{round(tr[2], 2)}$) borrows less information and
consequently yields the least peaked posterior, despite the standard error being
the smallest (\ie{} $\sigma_{r3} = \Sexpr{round(sr[2], 2)}$). In this case, the
conflict with the original study even inflates the variance of posterior
compared to the isolated replication posterior given by dashed blue line.


\subsection{Hypothesis testing}
\label{sec:hypothesis-testing}

Apart from the estimation of $\theta$ and $\alpha$, one may also wish to test
hypotheses regarding these parameters. A principled Bayesian approach is to
quantify the strength of evidence that the data provide for two competing
hypotheses $\h{j}$ and $\h{k}$ about the parameters, say, by computing the Bayes
factor $\BF_{jk}(\that_r) = f(\that_r \given \h{j})/f(\that_r \given \h{k})$,
with
\begin{align}
    \label{eq:marglikpow}
    f(\that_r \given \h{i}) = \int \Nor(\that_r \given \theta, \sigma^2_r) \,
    f(\theta, \alpha \given \h{i}) \,\text{d}\theta\,\text{d}\alpha
\end{align}
the marginal likelihood of the replication data $\that_r$ under hypothesis
$i \in \{k, j\}$. The Bayes factor can either be interpreted as the updating
factor of the prior odds to the posterior odds of the hypotheses $\h{j}$ and
$\h{k}$, or as the relative accuracy with which $\h{j}$ and $\h{k}$ predict the
data \citep{Good1958, Jeffreys1961, Kass1995}.


\subsubsection{Hypotheses about the effect size \texorpdfstring{$\boldsymbol{\theta}$}{}}

One is often interested in quantifying the evidence for a non-zero effect size
$\theta$ by testing $\h{0} \colon \theta = 0$ against
$\h{1} \colon \theta \neq 0$. This requires the specification of a prior
distribution for $\theta$ under $\h{1}$, and a natural choice is to use the
normalized power prior based on the original data along with a beta prior for
the power parameter as in~\eqref{eq:ppjoint}. The associated Bayes factor is
then given by
\begin{align}
  \BF_{01}(\that_{r}\given x, y)
  &= \frac{f(\that_{r} \given \h{0})}{f(\that_{r} \given \h{1})}
    =  \frac{\Nor(\that_{r}\given 0, \sigma^{2}_{r})}{\int_{0}^{1} \Nor(\that_{r}\given \that_{o},
      % \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha) \, f(\alpha \given \h{1}) \, \text{d}\alpha}.
    \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha) \, \Be(\alpha\given x, y) \, \text{d}\alpha}.
    % because of S-D ratio this is also given by
    % \frac{f(\theta = 0 \given \that_r, \that_o, \sigma_o, \sigma_r)}{f(\theta = 0)}
    % the ratio of marginal posterior to marginal prior evaluated at zero
  \label{eq:bf01}
\end{align}
An intuitively reasonable choice for the prior of $\alpha$ under $\h{1}$ is a
uniform $\alpha \sim \Be(1, 1)$ distribution. However, it is worth noting that
assigning a point mass $\alpha = 1$ leads to
\begin{align}
  \BF_{01}(\that_{r}\given \alpha = 1)
    =  \frac{\Nor(\that_{r}\given 0, \sigma^{2}_{r})}{ \Nor(\that_{r}\given \that_{o},
    \sigma^{2}_{o} + \sigma^{2}_{r})},
  \label{eq:bfr}
\end{align}
which is the \emph{replication Bayes factor} under normality
\citep{Verhagen2014, Ly2018, Pawel2020b}, that is, the Bayes factor contrasting
a point null hypothesis to the posterior distribution of the effect size based
on the original data (and in this case a uniform initial prior). A fixed
$\alpha = 1$ can also be seen as the limiting case of a beta prior with $y > 0$
and $x \to \infty$. The power prior version of the replication Bayes factor is
thus a generalization of the standard replication Bayes factor, one that allows
the original data to be discounted to some degree.

\subsubsection{Hypotheses about the power parameter \texorpdfstring{$\boldsymbol{\alpha}$}{}}

In order to quantify the compatibility between the original and the replication
study we may be interested in testing hypotheses regarding the power parameter
$\alpha$. For example, we may wish to test $\h{\text{c}} \colon \alpha = 1$
(``compatible'') versus $\h{\text{d}} \colon \alpha < 1$ (``different''). One
approach is to assign a point prior $\h{\text{d}}\colon\alpha = 0$. This leads
to the issue that for a flat initial prior $f(\theta) \propto 1$, the power
prior with $\alpha = 0$ is not proper and so the resulting Bayes factor is only
defined up to an arbitrary constant. Instead of the flat prior, we may thus
assign an uninformative but proper initial prior to $\theta$, for instance, a
unit-information prior $\theta \sim \Nor(0, \kappa^{2})$ with $\kappa^{2}$ the
variance from one (effective) observation \citep{Kass1995b} as it encodes
minimal prior information about the direction or magnitude of the effect size
\citep{Best2021}. This leads to the Bayes factor
\begin{align}
  \BF_{\text{dc}}(\that_{r} \given \kappa^{2})
  &= \frac{f(\that_{r} \given \h{\text{d}})}{f(\that_{r}
    \given \h{\text{c}})}
    = \frac{\Nor(\that_{r}\given0, \sigma^{2}_{r} + \kappa^{2})}{\Nor(\that_{r}\given s  \that_{o}, \sigma^{2}_{r} + s  \sigma^{2}_{o})}
    \label{eq:bfalpha}
\end{align}
with $s = \kappa^{2} / (\sigma^{2}_{o} + \kappa^{2})$.

An alternative approach that avoids the specification of a proper initial prior
for $\theta$ is to assign a prior to $\alpha$ under $\h{\text{d}}$. A suitable
class of priors is given by $\alpha \given \h{\text{d}}\sim \Be(1, y)$ with
$y > 1$. The $\Be(1, y)$ prior has its highest density at $\alpha = 0$ and is
monotonically decreasing. The parameter $y$ determines how much mass is assigned
to small values of $\alpha$. The resulting Bayes factor is then given by
\begin{align}
  \label{eq:bfdcrandom}
  \BF_{\text{dc}}(\that_{r}\given y)
  &=  \frac{\int_{0}^{1}\Nor(\that_{r}\given\that_{o}, \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha) \,
    \Be(\alpha\given 1, y) \, \text{d}\alpha}{\Nor(\that_{r}\given\that_{o}, \sigma^{2}_{r}
    + \sigma^{2}_{o})},
\end{align}
and the simple hypothesis $\h{\text{d}} \colon \alpha = 0$ can be seen as a
limiting case when $y \to \infty$.


\subsubsection{Example ``\Sexpr{ex}'' (continued)}

Table~\ref{tab:hypothesis} displays the results of the proposed hypothesis tests
applied to the three replications of the ``\Sexpr{ex}'' experiment. The Bayes
factors contrasting $\h{0}\colon \theta = 0$ to $\h{1}\colon \theta \neq 0$ with
normalized power prior with uniform prior for the power parameter $\alpha$ under
the alternative (column $\BF_{01}(\hat{\theta}_r \given x =1, y =1)$) indicate
absence of evidence for either hypothesis in the first replication, but decisive
evidence for $\h{1}$ in the second and third replication. In all three cases,
the Bayes factors are close to the standard replication Bayes factors with
$\alpha = 1$ under the alternative (column
$\BF_{01}(\hat{\theta}_r \given \alpha = 1)$).

\begin{table}[!htb]
  \centering
  \caption{Hypothesis tests for replications of experiment ``\Sexpr{ex}'' with
    original standardized mean difference effect estimate
    $\that_{o} = \Sexpr{round(to, 2)}$ and standard error
    $\sigma_{o} = \Sexpr{round(so, 2)}$. Shown are replication effect estimates
    $\that_{r}$ with standard errors $\sigma_{r}$, Bayes factors contrasting
    $\h{0}\colon \theta = 0$ to $\h{1} \colon \theta \neq 0$ with either uniform
    prior ($x = 1$, $y = 1$) assigned to $\alpha$ or fixed $\alpha = 1$ under
    $\h{1}$, and Bayes factors contrasting $\h{\text{d}}\colon \alpha < 1$ to
    $\h{\text{c}}\colon \alpha = 1$ with either initial unit-information prior
    $\theta \sim \Nor(0, \kappa^2)$ and $\h{\text{d}} \colon \alpha = 0$ or
    $\alpha \given \h{\text{d}} \sim \Be(1, y)$ prior under $\h{\text{d}}$.}
  \label{tab:hypothesis}
\resizebox{1\textwidth}{!}{%
<< "table-Bayes-factors", results = "asis" >>=
## Function to nicely format Bayes factors
.formatBF_ <- function(BF, digits = "default") {
    ## check inputs
    stopifnot(
        length(BF) == 1,
        is.numeric(BF),
        (is.finite(BF) && 0 < BF) || is.na(BF),

        length(digits) == 1,
        (is.character(digits) && digits == "default") ||
        (is.numeric(digits) && 0 <= digits)
    )
    ## return NA if input NA/NaN
    if (is.na(BF) || is.nan(BF))
        result <- NA
    else {
        ## format BF
        if (digits == "default") {
            if (BF < 1/1000)
                result <- "< 1/1000"
            if ((BF >= 1/1000) & (BF <= 1/10))
                result <- paste0("1/", as.character(round(1/BF)))
            if ((BF > 1/10) & (BF < 1))
                result <- paste0("1/", as.character(round(1/BF, digits = 1)))
            if ((BF < 10) & (BF >= 1))
                result <- as.character(round(BF, digits = 1))
            if ((BF >= 10) & (BF <= 1000))
                result <- as.character(round(BF))
            if (BF > 1000)
                result <- "> 1000"
        } else {
            if (BF < 1)
                result <- paste0("1/", as.character(round(1/BF, digits = digits)))
            else
                result <- as.character(round(BF, digits = digits))
        }
        ## when 1/1 return 1
        if (result == "1/1") result <- "1"
    }
    return(result)
}
formatBF <- Vectorize(FUN = .formatBF_)

## Parameters for Bayes factors
k <- sqrt(2) # unit-information standard deviation
x <- 1 # uniform prior for effect size BF
y <- 1 # uniform prior for effect size BF
yd <- 2 # monotonically decreasing prior for power parameter BF

## Compute BFs for effect sizes and power parameter
bfDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    bf01 <- bfPPtheta(tr = tr[i], sr = sr[i], to = to, so = so, x = x, y = y)
    bfr <- bfPPtheta(tr = tr[i], sr = sr[i], to = to, so = so, alpha = 1)
    bfdc <- bfPPalpha(tr = tr[i], sr = sr[i], to = to, so = so, uv = k^2)
    bfdcRandom <- bfPPalpha(tr = tr[i], sr = sr[i], to = to, so = so, y = yd)
    out <- data.frame(number = rnumber[i], tr = tr[i], sr = sr[i], bf = bf01,
                      bfr = bfr, bfdc = bfdc, bfdcRandom = bfdcRandom)
    return(out)
}))

## Create LaTeX table
dfTab <- bfDF %>%
    mutate(bf = formatBF(bf),
           bfr = formatBF(bfr),
           bfdc = formatBF(bfdc),
           bfdcRandom = formatBF(bfdcRandom),
           tr = round(tr, 2),
           sr = round(sr, 2),
           number = as.integer(number)) %>%
    arrange(tr)
xtab <- xtable(dfTab)
colnames(xtab) <- c("",
                    "$\\hat{\\theta}_r$",
                    "$\\sigma_r$",
                    paste0("$\\BF_{01}(\\hat{\\theta}_r \\given x =", x, ", y =", y, ")$"),
                    "$\\BF_{01}(\\hat{\\theta}_r \\given \\alpha = 1)$",
                    paste0("$\\BF_{\\text{dc}}(\\hat{\\theta}_r \\given \\kappa^2 =",
                           k^2, ")$"),
                    paste0("$\\BF_{\\text{dc}}(\\hat{\\theta}_r \\given y = ",
                           yd, ")$"))
align(xtab) <- rep("c", length(colnames(xtab)) + 1)
print(xtab, floating = FALSE, include.rownames = FALSE,
      sanitize.text.function = function(x){x}, booktabs = TRUE)
@
%
}
\end{table}

In order to compute the Bayes factor for testing $\h{\text{d}}\colon \alpha = 0$
versus $\h{\text{c}}\colon \alpha = 1$ we need to specify a unit variance for
the unit-information prior. A crude approximation for the variance of a
standardized mean difference effect estimate is given by
$\Var(\that_i) = 4/n_{i}$ with $n_{i}$ the total sample size of the study, and
assuming equal sample size in both groups \citep[p. 5]{Hedges2021}. We may thus
set the variance of the unit-information prior to $\kappa^{2} = 2$ since at
least one observation from each group is required to estimate a standardized
mean difference (assuming the variance is known). Based on this choice, the
Bayes factors $\BF_{\text{dc}}(\hat{\theta}_r \given \kappa^2 =2)$ in
Table~\ref{tab:hypothesis} indicate that the data provide substantial and strong
evidence for $\h{\text{c}}$ in the first and second replication study,
respectively, whereas the data indicate strong evidence for $\h{\text{d}}$ in
the third replication study. The Bayes factor
$\BF_{\text{dc}}(\hat{\theta}_r \given y = 2)$ in the right-most column with
$\alpha \given \h{\text{d}} \sim \Be(1, 2)$ prior assigned under the hypothesis
$\h{\text{d}}$ indicates absence of evidence for either hypothesis in the first
and second replication, but strong evidence for $\h{\text{d}}$ in the third
replication. Compared to the Bayes factor with $\h{\text{c}}\colon \alpha = 0$,
the results are thus more ambiguous for the first two replications but more
compelling for the third replication.

To conclude, our analysis suggests that only the second replication was
successful in the sense that it is both compatible with the original study while
also providing evidence against a null effect. The first replication is
compatible but does not provide evidence for a non-zero effect, whereas the
third replication provides much evidence for a a non-zero effect but is
incompatible with the original study.

\subsubsection{Bayes factor asymptotics}

<< "asymptotic-Bayes-factor" >>=
## Compute bound for the Bayes factor
k <- sqrt(2)
g <- k^2/so^2
s <- g/(1 + g)
trueESmin <- to ## minimized for true effect size = original effect estimate
bfBound <- dnorm(x = trueESmin, mean = 0, sd = k)/
    dnorm(x = trueESmin, mean = s*to, sd = sqrt(s)*so)
bfBound2 <- beta(3/2, 2)/beta(1, 2)
@

Some of the Bayes factors in the previous example provided only modest evidence
for the test-relevant hypotheses despite the large sample sizes in original and
replication study. It is therefore of interest to understand the asymptotic
behavior of the proposed Bayes factors. For instance, we may wish to understand
what happens when the standard error of the replication study $\sigma_{r}$
becomes arbitrarily small (through an increase in sample size). Assume that
$\that_{r}$ is a consistent estimator of its true underlying effect size
$\theta_r$, so that as the standard error $\sigma_r$ goes to zero, the estimate
will converge in probability to the true effect size $\theta_r$.

The limiting Bayes factors for testing the effect size $\theta$
from~\eqref{eq:bf01} and~\eqref{eq:bfr} are then given by
\begin{align*}
    \lim_{\sigma_{r} \downarrow 0} \BF_{\text{01}} (\that_r \given x, y)
    &= \frac{\delta(\theta_r) \, \sqrt{2\pi} \, \mbox{B}(x, y)}{\mbox{B}(x + 1/2, y)}
    \, M\bigg\{x+1/2, x + y + 1/2, -\frac{(\theta_r - \that_o)^2}{2\sigma^2_o}\bigg\}^{-1}
\end{align*}
and
\begin{align*}
    \lim_{\sigma_{r} \downarrow 0} \BF_{\text{01}} (\that_r \given \alpha = 1)
    &= \frac{\delta(\theta_r)}{\Nor(\theta_r \given \that_o, \sigma^2_o)},
\end{align*}
with $\delta(\cdot)$ the Dirac delta function. Both Bayes factors are hence
consistent \citep{Bayarri2012} in the sense that they indicate overwhelming
evidence for the correct hypothesis (\ie{} the Bayes factors go to infinity/zero
if the true effect size $\theta_r$ is zero/non-zero). In contrast, the Bayes
factors for testing the power parameter $\alpha$ from~\eqref{eq:bfalpha}
and~\eqref{eq:bfdcrandom} converge to positive constants
\begin{align}
  \label{eq:boundsimple}
  \lim_{\sigma_{r} \downarrow 0} \BF_{\text{dc}} (\theta_r\given \kappa^2) =
    \sqrt{1 - s} \, \exp\left[
    -\frac{1}{2} \, \left\{\frac{\theta_r^{2}}{\kappa^{2}} -
    \frac{(\theta_r - s\that_{o})^{2}}{s\sigma^{2}_{o}}\right\}\right]
\end{align}
and
\begin{align}
  \label{eq:boundcomposite}
 \lim_{\sigma_{r} \downarrow 0} \BF_{\text{dc}}(\theta_r\given y)
  &= \frac{\mbox{B}(3/2, y)}{\mbox{B}(1, y)} \,
  M\left\{y, y + 3/2, \frac{(\theta_r - \that_o)^2}{2\sigma^2_o}\right\}.
\end{align}
The amount of evidence one can find for either hypothesis thus depends on the
original effect estimate $\that_{o}$, the standard error $\sigma_{o}$, and the
true effect size $\theta_r$. For instance, in the ``\Sexpr{ex}'' experiment we
have an original effect estimate $\that_{o} = \Sexpr{round(to, 2)}$ and standard
error $\sigma_{o} = \Sexpr{round(so, 2)}$. The bound~\eqref{eq:boundsimple} is
minimized for a true effect size equal to the original effect estimate
$\theta_r = \that_{o} = \Sexpr{round(to, 2)}$, so the most extreme level we can
obtain is
$\lim_{\sigma_{r} \downarrow 0} \BF_{\text{dc}} (\theta_r\given \kappa^{2}=2) = \Sexpr{formatBF(bfBound)}$.
Similarly, the bound~\eqref{eq:boundcomposite} is minimized for
$\theta_r = \that_{o} = 0.21$ since then the confluent hypergeometric function
term becomes one, leading to
$\lim_{\sigma_{r} \downarrow 0} \BF_{\text{dc}} (\theta_r\given y = 2) = \mbox{B}(3/2, y)/\mbox{B}(1,y) = \Sexpr{formatBF(bfBound2)}$.
Even in a perfectly precise replication study we cannot find more evidence.


While the Bayes factors~\eqref{eq:bfalpha} and~\eqref{eq:bfdcrandom} are
inconsistent if the replication data become arbitrarily informative, the
situation is different when also the original data become arbitrarily
informative (reflected by also the standard error $\sigma_o$ going to zero and
the original effect estimate $\that_o$ converging to its true effect size
$\theta_o$). The Bayes factor with $\h{\text{d}}\colon \alpha = 0$
from~\eqref{eq:bfalpha} is then consistent as the the
limit~\eqref{eq:boundsimple} goes correctly to infinity/zero if the true effect
size of the replication study $\theta_r$ is different/equivalent from the true
effect size of the original study $\theta_o$. In contrast, the Bayes factor with
$\alpha \given \h{\text{d}} \sim \Be(1, y)$ from~\eqref{eq:bfdcrandom} is still
inconsistent since it only shows the correct asymptotic behavior when the true
effect sizes are unequal (\ie{} the Bayes factor goes to infinity) but not when
the effect sizes are equivalent, in which case it is still bounded by
$\mbox{B}(3/2, y)/\mbox{B}(1,y)$.

\subsection{Design of replication studies}
\label{sec:design}
Now assume that the replication study has not yet been conducted and we wish to
plan for a suitable sample size for a hypothesis test as described previously.
In the case of the replication Bayes factor under normality~\eqref{eq:bfr},
\citet{Pawel2020b} derived the probability of replication success in closed form
under $\h{0}$ and $\h{1}$. Based on their result, standard Bayesian design
analysis \citep{Weiss1997, DeSantis2004, Schoenbrodt2017} can be conducted to
determine the appropriate replication sample size. For the generalized
replication Bayes factor~\eqref{eq:bf01}, numerical integration or simulation is
required to compute the probability of replication success as the marginal
likelihood is not available in closed form under $\h{1}$ in general.

It is also possible to derive the probability of replication success at some
level $\gamma$ analytically for the Bayes factor~\eqref{eq:bfalpha}. With some
algebra, one can show that $\BF_{\text{dc}} \leq \gamma$ is equivalent to
% \begin{align*}
%   2\log\gamma - \log\left(\frac{\sigma^{2}_{r} + s  \sigma^{2}_{o}}{
%   \sigma^{2}_{r} + \kappa^{2}}\right)
%   &\geq \frac{(\that_{r} - s  \that_{o})^{2}}{
%   \sigma^{2}_{r} + s  \sigma^{2}_{o}} - \frac{\that_{r}^{2}}{\sigma^{2}_{r} +
%   \kappa^{2}} \\
%   &= \frac{\kappa^{2} - s  \sigma^{2}_{o}}{(\sigma^{2}_{r} + \kappa^{2})
%     (\sigma^{2}_{r} + s  \sigma^{2}_{o})} \left(\that_{r} -
%     \frac{s \that_{o} \, (\sigma^{2}_{r} + \kappa^{2})}{\kappa^{2} -
%     s  \sigma^{2}_{o}}\right)^{2}
% \end{align*}
% which is equivalent to
\begin{align}
  \left\{\that_{r} -
%   \frac{s \that_{o} (\sigma^{2}_{r} + \kappa^{2})}{\kappa^{2} - s  \sigma^{2}_{o}}
  \frac{\that_o \, (\sigma^{2}_{r} + \kappa^{2})}{\kappa^2}\right\}^{2}
  \leq X  \label{eq:RScond}
\end{align}
with
\begin{align*}
    X =&
    \frac{(\sigma^{2}_{r} + \kappa^{2})(\sigma^{2}_{r} +
    s  \sigma^{2}_{o})}{\kappa^{2} - s  \sigma^{2}_{o}}
    \left\{\log\gamma^{2}- \log\left(\frac{\sigma^{2}_{r} + s  \sigma^{2}_{o}}{
            \sigma^{2}_{r} + \kappa^{2}}\right) - \frac{s^{2}  \that^{2}_{o}}{s  \sigma^{2}_{o} - \kappa^{2}}\right\}
\end{align*}
and $s = \kappa^{2}/(\sigma^{2}_{o} + \kappa^{2})$. Denote by $m_{i}$ and
$v_{i}$ the mean and variance of $\that_{r}$ under hypothesis
$i \in \{\text{d}, \text{c}\}$. The left hand side of~\eqref{eq:RScond} then
follows a scaled non-central chi-squared distribution under both hypotheses.
Hence the probability of replication success is given by
\begin{align}
  \Pr(\BF_{\text{dc}} \leq \gamma \given \h{i})
  &= \Pr\left(\chi^{2}_{1,\lambda_{i}} \leq X/v_{i} \right)
    \label{eq:PRS}
\end{align}
with non-centrality parameter
\begin{align*}
  \lambda_{i}
  = \left\{m_{i} -
  %\frac{s \that_{o}  (\sigma^{2}_{r} + \kappa^{2})}{\kappa^{2}  - s  \sigma^{2}_{o}}
  \frac{\that_o \, (\sigma^{2}_{r} + \kappa^{2})}{\kappa^2}
  \right\}^{2} \big / v_{i}.
\end{align*}

To determine the replication sample size, we can now use~\eqref{eq:PRS} to
compute the probability of replication success at a desired level $\gamma$ over
a grid of replication standard errors $\sigma_{r}$, and under either hypothesis
$\h{\text{d}}$ and $\h{\text{c}}$. The appropriate standard error $\sigma_r$ is
then chosen so that the probability for finding correct evidence is sufficiently
high under the respective hypothesis, and sufficiently low under the wrong
hypothesis. Subsequently, the standard error $\sigma_{r}$ needs to be translated
into a sample size, \eg{} for standardized mean differences via the
aforementioned approximation $n_{r} \approx 4/\sigma^{2}_{r}$.


\begin{figure}[!htb]
<< "Bayes-factor-design-analysis", fig.height = 4.5 >>=
## Function to compute probability of replication success
powerFun <- function(sr, to, so, k, level, mi, vi) {
    s <- k^2 / (so^2 + k^2)
    X <- (sr^2 + k^2) * (sr^2 + s * so^2) / (k^2 - s * so^2) *
        (2 * log(level) - log((sr^2 + s * so^2) / (sr^2 + k^2)) -
         s^2*to^2/(s*so^2 - k^2))
    ## lambdai <- (mi - s * to * (sr^2 + k^2) / (k^2 - s * so^2))^2/vi
    lambdai <- (mi - to * (sr^2 + k^2) / k^2)^2/vi
    p <- stats::pchisq(q = X/vi, df = 1, ncp = lambdai, lower.tail = TRUE)
    return(p)
}

## Compute proability of replication success for a grid of relative
## variances (c = so^2/sr^2 =~ nr/no)
cSeq <- exp(seq(log(1/12), log(12), length.out = 1000))
cbks <- c(1/10, 1/3, 1, 3, 10)
level <- 1/10
plotDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    to <- tr[i]
    so <- sr[i]
    srSeq <- so / sqrt(cSeq)
    ## mean and variance under Hd and Hc
    md <- 0
    vd <- srSeq^2 + k^2
    s <- k^2/so^2 / (1 + k^2/so^2)
    mc <- s*to
    vc <- srSeq^2 + s*so^2
    ## power to achieve BF < level
    p1Hd <- powerFun(sr = srSeq, to = to, so = so, k = k, level = level,
                     mi = md, vi = vd)
    p1Hc <- powerFun(sr = srSeq, to = to, so = so, k = k, level = level,
                     mi = mc, vi = vc)
    outDF1 <- rbind(data.frame(p = p1Hd, level = level, type = "italic(H['d'])",
                               sr = srSeq, c = cSeq, to = to, so = so,
                               direction = "<="),
                    data.frame(p = p1Hc, level = level, type = "italic(H['c'])",
                               sr = srSeq, c = cSeq, to = to, so = so,
                               direction = "<="))
    ## power to achieve BF > 1/level
    p2Hd <- 1 - powerFun(sr = srSeq, to = to, so = so, k = k, level = 1/level,
                         mi = md, vi = vd)
    p2Hc <- 1 - powerFun(sr = srSeq, to = to, so = so, k = k, level = 1/level,
                         mi = mc, vi = vc)
    outDF2 <- rbind(data.frame(p = p2Hd, level = 1/level, type = "italic(H['d'])",
                               sr = srSeq, c = cSeq, to = to, so = so,
                               direction = ">="),
                    data.frame(p = p2Hc, level = 1/level, type = "italic(H['c'])",
                               sr = srSeq, c = cSeq, to = to, so = so,
                               direction = ">="))
    outDF <- rbind(outDF1, outDF2)
    outDF$yFacetLab <- paste0("'Pr(BF'['dc']", outDF$direction,
                              formatBF(outDF$level),
                              "~ '|' ~ italic(H['i']) *", "')'")
    outDF$xFacetLab <- paste0("{hat(theta)[italic(o)] ==",
                              round(outDF$to, 2),
                              "}*', '*sigma[italic(o)] == ",
                              round(outDF$so, 2))
    return(outDF)
}))

## Determine replication standard error such that certain power is achieved
pow <- 0.8
ssDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    to <- tr[i]
    so <- sr[i]
    ## standard error to achieve P(BF < level | Hc, sr) = 0.8
    rootFunHc <- function(c) {
        sr <- so/sqrt(c)
        mc <- s*to
        vc <- sr^2 + s*so^2
        powerFun(sr = sr, to = to, so = so, k = k, level = level,
                 mi = mc, vi = vc) - pow
    }
    resHd <- try(uniroot(f = rootFunHc, interval = c(1/100, 100))$root)
    if (class(resHd) == "try-error") {
        srHc <- NaN
    } else {
        srHc <- so/sqrt(resHd)
    }
    ## standard error to achieve P(BF > 1/level | Hd, sr) = 0.8
    rootFunHd <- function(c) {
        sr <- so/sqrt(c)
        md <- 0
        vd <- sr^2 + k^2
        (1 - powerFun(sr = sr, to = to, so = so, k = k, level = 1/level,
                      mi = md, vi = vd)) - pow
    }
    resHd <- try(uniroot(f = rootFunHd, interval = c(1/100, 100))$root)
    if (class(resHd) == "try-error") {
        srHd <- NaN
    } else {
        srHd <- so/sqrt(resHd)
    }
    outDF <- rbind(data.frame(level = 1/level, type = "italic(H['d'])",
                              sr = srHd, c = so^2/srHd^2, to = to, so = so,
                              direction = ">=", power = pow),
                   data.frame(level = level, type = "italic(H['c'])",
                              sr = srHc, c = so^2/srHc^2, to = to, so = so,
                              direction = "<=", power = pow))
    outDF$yFacetLab <- paste0("'Pr(BF'['dc']", outDF$direction,
                              formatBF(outDF$level),
                              "~ '|' ~ italic(H['i']) *", "')'")
    outDF$xFacetLab <- paste0("{hat(theta)[italic(o)] ==",
                              round(outDF$to, 2),
                              "}*', '*sigma[italic(o)] == ",
                              round(outDF$so, 2))
    return(outDF)
}))

## colorblind friendly scale
ncat <- length(unique(plotDF$type))
colblind <- palette.colors(n = ncat + 1, palette = "Okabe-Ito")[2:(ncat + 1)]
names(colblind) <- unique(plotDF$type)

## Plot power curves and required standard errors
powbks <- seq(0, 1, 0.2)
ggplot(data = plotDF, aes(x = c, y = p, color = type)) +
    facet_grid(yFacetLab ~ xFacetLab, labeller = label_parsed,
               switch = "y") +
    geom_hline(yintercept = pow, lty = 2, alpha = 0.1) +
    geom_line(alpha = 0.9, size = 0.7) +
    geom_point(data = ssDF, aes(x = c, y = power), size = 0.8,
               show.legend = FALSE) +
    geom_segment(data = ssDF, aes(x = c, xend = c, y = power, yend = 0),
                 alpha = 0.3, arrow = arrow(length = unit(0.15, "cm")),
                 show.legend = FALSE, size = 0.5) +
    labs(x = bquote("Relative variance" ~ sigma[italic(o)]^2/sigma[italic(r)]^2  %~~%
                        italic(n[r]) / italic(n[o])),
         y = NULL, color = NULL) +
    scale_y_continuous(breaks = powbks, labels = scales::percent,
                       limits = c(0, 1)) +
    ## scale_color_brewer(palette = "Dark2", labels = scales::parse_format()) +
    scale_color_manual(values = colblind, labels = scales::parse_format()) +
    scale_x_log10(breaks = cbks, labels = formatBF(cbks)) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(),
          strip.background.y = element_blank(), strip.placement = "outside")
@
\caption{Probability of replication success as a function of relative variance
  for the three replications of experiment ``Labels'' regarded as original
  study. The arrows point to the relative variance associated with an
  \Sexpr{round(100*pow, 2)}\% probability under the respective hypotheses.}
\label{fig:ssd}
\end{figure}


\subsubsection{Example ``\Sexpr{ex}'' (continued)}

Figure~\ref{fig:ssd} illustrates Bayesian design analysis based on the power
parameter Bayes factor $\BF_{\text{dc}}(\that_{r} \given \kappa^{2})$
from~\eqref{eq:bfalpha}. The three replication studies from the experiment
``Labels'' are now regarded as original studies, and each column of the figure
shows the corresponding design analyses for future replications. In each plot,
the probability for finding strong evidence for $\h{\text{c}}\colon \alpha = 1$
(top) or $\h{\text{d}}\colon \alpha = 0$ (bottom) is shown as a function of the
relative sample size. In both cases, the probability is computed assuming that
either $\h{\text{c}}$ (blue) or $\h{\text{d}}$ (yellow) is true.

The curves look more or less similar for all three studies. We see from the
lower panels that the probability for finding strong evidence for $\h{\text{d}}$
is not much affected by the sample size of the replication study; it stays at
almost zero under $\h{\text{c}}$, while under $\h{\text{d}}$ it increases from
about 75\% to about 90\%. In contrast, the top panels show that the probability
for finding strong evidence for $\h{\text{c}}$ rapidly increases under
$\h{\text{c}}$ and seems to level off at an asymptote. Under $\h{\text{d}}$ the
probability stays below 5\% across the whole range.

The plots also display the required relative sample size to obtain strong
evidence with probability of  $\Sexpr{round(100*pow, 2)}\%$ under the correct
hypothesis. We see that original studies with smaller standard errors require
smaller relative sample sizes in the replication to achieve the same probability
of replication success. Under $\h{\text{c}}$ the required relative sample sizes
are larger than under $\h{\text{d}}$. However, while the probability of
misleading evidence under $\h{\text{c}}$ seems to be well controlled under the
determined sample size, under $\h{\text{d}}$ it stays roughly 5\% for all three
studies, and even for very large replication sample sizes. Choosing the sample
size based on finding strong evidence for $\h{\text{c}}$ assuming $\h{\text{c}}$
is true thus guarantees appropriate error probabilities for finding strong
evidence for $\h{\text{d}}$ in all three studies. At the same time, it seems
that the probability for finding misleading evidence for $\h{\text{c}}$ cannot
be reduced below around 5\% which might undesirably high for certain
applications.


\section{Connection to hierarchical modeling of replication studies}
\label{sec:hierarch}

Hierarchical modeling is another approach that allows for the incorporation of
historical data in Bayesian analyses; moreover, hierarchical models have
previously been used in the replication setting \citep{Bayarri2002,
  Bayarri2002b, Pawel2020}. We will now investigate how the hierarchical
modeling approach is related to the power prior approach in the analysis of
replication studies, both in parameter estimation and hypothesis testing.

\subsection{Connection to parameter estimation in hierarchical models}

Assume a hierarchical model
\begin{subequations}
\label{eq:hierarch-model}
\begin{align}
  \that_{i} \given \theta_{i}\, &\sim \Nor(\theta_{i}, \sigma^{2}_{i}) \\
  \theta_{i} \given \theta_{*} &\sim \Nor(\theta_{*}, \tau^{2}) \\
  f(\theta_{*}) &\propto k
\end{align}
\end{subequations}
where for study $i \in \{o ,r\}$ the effect estimate $\that_i$ is normally
distributed around a study specific effect size $\theta_i$ which itself is
normally distributed around an overall effect size $\theta_{*}$. The
heterogeneity variance $\tau^2$ determines the similarity of the study specific
effect sizes $\theta_i$. The overall effect size $\theta_*$ is assigned an
(improper) flat prior $f(\theta_{*}) \propto k$, for some $k > 0$, which is a
common approach in hierarchical modeling of effect estimates \citep{Rover2021}.

We show in Appendix~\ref{app:postHierarch} that under the hierarchical
model~\eqref{eq:hierarch-model} the marginal posterior distribution of the
replication specific effect size $\theta_{r}$ is given by
\begin{align}
  \label{eq:posthierarch}
  \theta_{r} \given \that_{o}, \that_{r}, \tau^{2}
  \sim \Nor\left(\frac{\that_{r}/\sigma^{2}_{r} + \that_{o}/(2\tau^{2} +
  \sigma^{2}_{o})}{1/\sigma^{2}_{r} + 1/(2\tau^{2} + \sigma^{2}_{o})},
  \frac{1}{1/\sigma^{2}_{r} + 1/(2\tau^{2} + \sigma^{2}_{o})}\right),
\end{align}
that is, a normal distribution whose mean is a weighted average of the
replication effect estimate $\that_r$ and the original effect estimate
$\that_o$. The amount of shrinkage of the replication towards the original
effect estimate depends on how large the replication standard error $\sigma_r$
is relative to the heterogeneity variance $\tau^2$ and the original standard
error $\sigma_o$. There exists a correspondence between the posterior for the
replication effect size $\theta_r$ from hierarchical
model~\eqref{eq:posthierarch} and the posterior for the effect size $\theta$
under the power prior approach. Specifically, note that under the power prior
and for a fixed power parameter $\alpha$, the posterior of the effect size
$\theta$ is given by
\begin{align}
  \label{eq:postpower}
  \theta \given \that_{o}, \that_{r}, \alpha
  \sim \Nor\left(\frac{\that_{r}/\sigma^{2}_{r} +
  (\that_{o}\alpha)/\sigma^{2}_{o}}{1/\sigma^{2}_{r} + \alpha/\sigma^{2}_{o}},
  \frac{1}{1/\sigma^{2}_{r} + \alpha/\sigma^{2}_{o}}\right).
\end{align}
The hierarchical posterior ~\eqref{eq:posthierarch} and the power prior
posterior~\eqref{eq:postpower} thus match if and only if
\begin{align}
  \alpha = \frac{\sigma^{2}_{o}}{2\tau^{2} + \sigma^{2}_{o}},
  % &\text{respectively}&
  % &\tau^{2} = \left(\frac{1}{\alpha} - 1\right) \,
  %   \frac{\sigma^{2}_{o}}{2}
  \label{eq:tau2alpha}
\end{align}
respectively
\begin{align}
  \tau^{2} = \left(\frac{1}{\alpha} - 1\right) \, \frac{\sigma^{2}_{o}}{2},
  \label{eq:alpha2tau}
\end{align}
which was first shown by \citet{Chen2006}. For instance, a power prior model
with $\alpha = 1$ corresponds to a hierarchical model with $\tau^{2} = 0$, and a
hierarchical model with $\tau^2 \to \infty$ corresponds to a power prior model
with $\alpha \downarrow 0$. In between these two extremes, however, $\alpha$ has
to be interpreted as a relative measure of heterogeneity since the
transformation to $\tau^2$ involves a scaling by the variance $\sigma^2_o$ of
the original effect estimate. For this reason, there is a direct correspondence
between $\alpha$ and the popular relative heterogeneity measure
$I^{2} = \tau^{2}/(\tau^{2} + \sigma^{2}_o)$ \citep{Higgins2002} computed from
$\tau^2$ and the variance of the original estimate $\sigma^2_o$, that is,
\begin{align*}
  \alpha = \frac{1 - I^{2}}{1 + I^{2}},
\end{align*}
with inverse of the same functional form. Figure~\ref{fig:I2} shows $\alpha$ and
the corresponding $\tau^2$ and $I^2$ values which lead to matching posteriors.
The relationship between $I^2$ and $\alpha$ seems not too far off from linear.
Therefore, a rough and ready heuristic to connect power priors to hierarchical
models is $\alpha \approx 1 - I^2$.

\begin{figure}[!htb]
<< "figure-I2-alpha", fig.height = 3 >>=
## Compute alpha from I^2 and I
I2seq <- seq(from = 0, to = 1, length.out = 1000)
alphaseq <- (1 - I2seq)/(1 + I2seq)
I2DF <- data.frame(I2 = I2seq, alpha = alphaseq, tau2 = so^2/2*(1/alphaseq - 1))
I2DF$x <- I2DF$I2
I2DF$type <- "italic('I')^2"
IDF <- I2DF
IDF$x <- sqrt(I2DF$x)
IDF$type <- "italic('I')"

## compute alpha from tau^2
tau2seq <- seq(0, 0.1, length.out = 1000)
tauDF <- IDF
tauDF$x <- tau2seq
tauDF$alpha <-  so^2/(2*tau2seq + so^2)
tauDF$type <- "tau^2"

## Plot alpha as a function of tau, I, and I^2
plotDF <- rbind(I2DF, IDF, tauDF)
plotDF$type <- factor(plotDF$type, levels = c("tau^2", "italic('I')^2", "italic('I')"))
ggplot(data = filter(plotDF, type != "italic('I')"),
       aes(x = x, y = alpha)) +
    ## geom_abline(intercept = 1, slope = -1, alpha = 0.1) +
    geom_line() +
    facet_wrap(~ type, labeller = label_parsed,
               strip.position = "bottom", scales = "free_x") +
    theme_bw() +
    labs(x = NULL, y = bquote(alpha)) +
    theme(legend.position = "top", panel.grid.minor = element_blank(),
          strip.background.x = element_blank(), strip.placement = "outside",
          strip.text.x = element_text(size = 11))

@
\caption{The heterogeneity $\tau^{2}$ and relative heterogeneity
  $I^{2} = \tau^{2}/(\tau^{2} + \sigma^{2}_o)$ of a hierarchical model versus
  the power parameter $\alpha$ from a power prior model which lead to matching
  posteriors for the effect sizes $\theta$ and $\theta_{r}$. The variance of the
  original effect estimate $\sigma_{o}^2 = \Sexpr{round(so, 2)}^{2}$ from the
  ``\Sexpr{ex}'' experiment is used for the transformation to the heterogeneity
  scale $\tau^{2}$.}
\label{fig:I2}
\end{figure}

It has remained unclear whether or not a similar correspondence
% between hierarchical and power prior posteriors
exists in cases where $\alpha$ and $\tau^{2}$ are random and assigned prior
distributions. Here we confirm that there is indeed such a correspondence.
Specifically, the marginal posterior of the replication effect size $\theta_r$
from the hierarchical model matches with the marginal posterior of the effect
size $\theta$ from the power prior model if the prior density functions
$f_{\tau^2}(\cdot)$ and $f_{\alpha}(\cdot)$ of $\tau^2$ and $\alpha$ satisfy
\begin{align}
  \label{eq:matchCond}
  f_{\tau^2}(\tau^{2}) = f_{\alpha}\left(\frac{\sigma^{2}_{o}}{2 \tau^{2} + \sigma^{2}_{o}}\right) \,
  \frac{2\sigma^{2}_{o}}{(2 \tau^{2} + \sigma^{2}_{o})^{2}}
\end{align}
for every $\tau^2 \geq 0$, see Appendix~\ref{app:mapping} for details.
Importantly, the correspondence condition~\eqref{eq:matchCond} involves a
scaling by the variance from the original effect estimate $\sigma^2_o$, meaning
that also in this case $\alpha$ acts similar to a relative heterogeneity
parameter. This can also be seen from the correspondence condition between
$\alpha$ and $I^2 = \tau^2/(\sigma^2_o + \tau^2)$, which can be derived in
exactly the same way as the correspondence between $\alpha$ and $\tau^2$. That
is, the marginal posteriors of $\theta$ and $\theta_r$ match if the prior
density functions $f_{I^2}(\cdot)$ and $f_{\alpha}(\cdot)$ of $I^2$ and $\alpha$
satisfy
\begin{align}
  \label{eq:matchCondI2}
  f_{I^2}(I^{2}) = f_{\alpha}\left(\frac{1 - I^2}{1 + I^2}\right) \frac{2}{(1 + I^2)^2}
\end{align}
for every $0 \leq I^2 \leq 1$.

Interestingly, conditions~\eqref{eq:matchCondI2} and~\eqref{eq:matchCond} imply
that a beta prior on the power parameter $\alpha \sim \Be(x, y)$ corresponds to
a generalized F prior on the heterogeneity
$\tau^2 \sim \mbox{GF}(y, x, 2/\sigma^2_o)$ and a generalized beta prior on the
relative heterogeneity $I^2 \sim \mbox{GBe}(y, x, 2)$, see
Appendix~\ref{app:distribution} for details on both distributions. This
connection provides a convenient analytical link between hierarchical modeling
and power prior framework, as beta priors for $\alpha$ are almost universally
used in applications of power priors. The result also illustrates that the power
prior framework seems unnatural from the perspective of hierarchical modeling
since it corresponds to specifying priors on the $I^2$ scale rather than on the
$\tau^2$ scale. The same prior on $I^2$ will imply different degrees of
informativeness on the $\tau^2$ scale for original effect estimates $\that_o$
with different variances $\sigma^2_o$ since $I^2$ is entangled with the variance
of the original effect estimate.

\begin{figure}[!htb]
<< "figure-corresponding-priors", fig.height = 5 >>=
## Function for computing prior density of tau^2 based on the corresponding
## Beta(a, b) prior on power parameter alpha
ftau2 <- function(tau2, a, b, so) {
    dbeta(x = so^2/(2*tau2 + so^2), shape1 = a, shape2 = b) *
        2*so^2/(2*tau2 + so^2)^2
}

## check that integrates to one
## integrate(f = ftau2, lower = 0, upper = Inf, a = 0.5, b = 2, so = 0.05)

## Function for computing prior density of I^2 based on the corresponding
## Beta(a, b) prior on power parameter alpha
fi2 <- function(i2, a, b) {
   dbeta(x = (1 - i2)/(1 + i2), shape1 = a, shape2 = b) *
         2 / (1 + i2)^2
    ## VGAM::dlino(x = i2, shape1 = b, shape2 = a, lambda = 2)
}

## check that integrates to one
## integrate(f = fi2, lower = 0, upper = 1, a = 0.5, b = 2)

## Compute prior density of tau^2 for different Beta priors on alpha
paramsGrid <- data.frame(a = c(1, 2, 1), b = c(1, 1, 2))
aseq <- seq(0, 1, length.out = 500)
tau2seq <- seq(0, 0.09, length.out = 500)^2
alphaDF <- do.call("rbind", lapply(X = seq(1, nrow(paramsGrid)), FUN = function(i) {
    a <- paramsGrid$a[i]
    b <- paramsGrid$b[i]
    dens <- dbeta(x = aseq, shape1 = a, shape = b)
    out <- data.frame(x = aseq, xlab = "alpha", density = dens, a = a, b = b,
                      ylab = paste0("{italic(x) ==", a, "}*','~ italic(y) ==", b))
    return(out)
}))
tau2DF <- do.call("rbind", lapply(X = seq(1, nrow(paramsGrid)), FUN = function(i) {
    a <- paramsGrid$a[i]
    b <- paramsGrid$b[i]
    dens <- ftau2(tau2 = tau2seq, a = a, b = b, so = so)
    out <- data.frame(x = tau2seq, xlab = "tau^2", density = dens, a = a, b = b,
                      ylab = paste0("{italic(x) ==", a, "}*','~ italic(y) ==", b))
    return(out)
}))
i2DF <- do.call("rbind", lapply(X = seq(1, nrow(paramsGrid)), FUN = function(i) {
    a <- paramsGrid$a[i]
    b <- paramsGrid$b[i]
    dens <- fi2(i2 = aseq, a = a, b = b)
    out <- data.frame(x = aseq, xlab = "italic('I')^2",
                      density = dens, a = a, b = b,
                      ylab = paste0("{italic(x) ==", a, "}*','~ italic(y) ==", b))
    return(out)
}))
plotDF <- rbind(alphaDF, tau2DF, i2DF)
alphaDF$ylabFac <- factor(x = alphaDF$ylab, levels = unique(plotDF$ylab))
tau2DF$ylabFac <- factor(x = tau2DF$ylab, levels = unique(plotDF$ylab))
i2DF$ylabFac <- factor(x = i2DF$ylab, levels = unique(plotDF$ylab))

## Plot beta priors for alpha and corresponding priors for tau^2
plotalpha <- ggplot(data = alphaDF, aes(x = x, y = density)) +
    facet_grid(ylabFac ~ ., labeller = label_parsed, scales = "free",
               switch = "x") +
    geom_line() +
    labs(x = bquote(alpha), y = NULL) +
    expand_limits(y = c(0, 3)) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(),
          strip.background.x = element_blank(), strip.placement = "outside")

ploti2 <- ggplot(data = i2DF, aes(x = x, y = density)) +
    facet_grid(ylabFac ~ ., labeller = label_parsed,
               switch = "x") +
    geom_line() +
    labs(x = bquote(italic("I")^2), y = NULL) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(), strip.text.y = element_blank(),
          strip.background.x = element_blank(), strip.placement = "outside")

plottau <- ggplot(data = tau2DF, aes(x = x, y = density)) +
    facet_grid(ylabFac ~ ., labeller = label_parsed, scales = "free",
               switch = "x") +
    geom_line() +
    labs(x = bquote(tau^2), y = "Density") +
    ## scale_x_continuous(sec.axis = sec_axis(trans = ~ ./so^2,
    ##                                        name = bquote(tau^2/sigma[italic("o")]^2))) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(), strip.text.y = element_blank(),
          strip.background.x = element_blank(), strip.placement = "outside")


## Combine plots
ggpubr::ggarrange(plottau, ploti2, plotalpha, ncol = 3, align = "h",
                  widths = c(1.25, 1.05, 1.1))
@

\caption{Priors on the heterogeneity $\tau^2 \sim \mbox{GF}(y, x, 2/\sigma^2_o)$
(left), the relative heterogeneity
$I^2 = \tau^2/(\sigma^2_o + \tau^2) \sim \mbox{GBe}(y, x, 2)$ (middle) and the
power parameter $\alpha \sim \Be(x, y)$ (right) that lead to matching marginal
posteriors for effect sizes $\theta$ and $\theta_{r}$. The variance of the
original effect estimate $\sigma_{o}^2 = \Sexpr{round(so, 2)}^{2}$ from
the ``\Sexpr{ex}'' experiment is used for the transformation to the
heterogeneity scale $\tau^{2}$.}
\label{fig:matchingpriors}
\end{figure}

Figure~\ref{fig:matchingpriors} provides three examples of matching priors using
the variance of the original effect estimate from the ``Labels'' experiment for
the transformation to the heterogeneity scale $\tau^2$.
% In the context of regression models, a similar relationship between
% ``hyper $g$ priors'' on the relative variance parameter $g$ and beta
% priors on the corresponding shrinkage factor $g/(1 + g)$ was studied
% by \citet{Liang2008}.
The top row of Figure~\ref{fig:matchingpriors} shows that the uniform prior on
$\alpha$ corresponds to a
$f(\tau^{2}) \propto \sigma^{2}_{o}/(2\tau^{2} + \sigma^{2}_{o})^{2}$ prior
which is similar to the ``uniform shrinkage'' prior
$f(\tau^{2}) \propto \sigma^{2}_{o}/(\tau^{2} + \sigma^{2}_{o})^{2}$
\citep{Daniels1999}. This prior has the highest density at $\tau^{2} = 0$ but
still gives some mass to larger values of $\tau^{2}$. Similarly, on the scale of
$I^2$ the prior slightly favors smaller values. The middle row of
Figure~\ref{fig:matchingpriors} shows that the $\alpha \sim \Be(2, 1)$
prior--indicating more compatibility between original and replication than the
uniform prior--gives even more mass to small values of $\tau^{2}$ and $I^2$, and
also has the highest density at $\tau^2 = 0$ and $I^2 = 0$. In contrast, the
bottom row of Figure~\ref{fig:matchingpriors} shows that the
$\alpha \sim \Be(1, 2)$ prior--indicating less compatibility between original
and replication than the uniform prior--gives less mass to small $\tau^{2}$ and
$I^2$, and has zero density at $\tau^{2} = 0$ and $I^2 = 0$.

\subsection{Connection to hypothesis testing in hierarchical models}

Two types of hypothesis tests can be distinguished in the hierarchical model;
tests for the overall effect size $\theta_*$ and tests for the heterogeneity
variance $\tau^2$. In all cases, computations of marginal likelihoods of the
form
\begin{align}
    \label{eq:marglikhierarch}
    f(\that_r \given \h{i}) = \int \Nor(\that_r \given \theta_*, \sigma^2_r + \tau^2) \,
    % \, f(\theta_* \given \tau^2, \h{i}) \, f(\tau^2 \given \h{i})
    f(\theta_*, \tau^2 \given \h{i})
    \, \text{d}\theta_* \, \text{d}\tau^2
\end{align}
with $i \in \{j, k\}$ are required for obtaining Bayes factors
$\BF_{jk}(\that_r) = f(\that_r \given \h{j})/f(\that_r \given \h{k})$ which
quantify the evidence that the replication data $\that_r$ provide for a
hypothesis $\h{k}$ over a competing hypothesis $\h{j}$. Under each hypothesis a
joint prior for $\tau^2$ and $\theta_*$ needs to be assigned.

As with parameter estimation, it is of interest to investigate whether there is
a correspondence with hypothesis tests from the power prior framework from
Section~\ref{sec:hypothesis-testing}. For two tests to match, one needs to
assign priors to $\tau^2$ and $\theta_*$, respectively, to $\alpha$ and $\theta$
so that the marginal likelihood~\eqref{eq:marglikhierarch} equals the marginal
likelihood from the power prior model~\eqref{eq:marglikpow} under both
test-relevant hypotheses.

Concerning the generalized replication Bayes factor from~\eqref{eq:bf01} testing
$\h{0} \colon \theta = 0$ versus $\h{1} \colon \theta \neq 0$, one can show that
it matches with the Bayes factor contrasting $\h{0} \colon \theta_* = 0$ versus
$\h{1} \colon \theta_* \neq 0$ with
\begin{align*}
  &\h{0}\colon \theta_{*} = 0& &\text{versus}&
  \theta_{*} \given \tau^{2}, \h{1} &\sim \Nor(\that_{o}, \sigma^{2}_{o} + \tau^{2}) \\
  &\phantom{\h{0}\colon} \tau^{2} = 0& &&
  \tau^2 \given \h{1}&\sim \mbox{GF}(y, x, \sigma^2_o/2)
%   f(\tau^{2}) = \Be\left\{\alpha = \sigma^{2}_{o}/(\sigma^{2}_{o} +
%     2\tau^{2})\given x, y\right\}
%     (2\sigma^{2}_{o})/(2\tau^{2} + \sigma^{2}_o)^{2}&
    %     f(\tau^{2}) = f\{\tau^{2} = (1/\alpha - 1)\, (\sigma^{2}_{o}/2)\}\{\sigma^{2}_{o}/(2\alpha^{2})\}&
\end{align*}
for the replication data in in the hierarchical framework. The Bayes factor thus
compares the likelihood of the replication data under the hypothesis $\h{0}$
postulating that the global effect size $\theta_{*}$ is zero and that there is
no effect size heterogeneity, relative to the likelihood of the data under the
hypothesis $\h{1}$ postulating that $\theta_{*}$ follows the posterior based on
the original data and an initial flat prior for $\theta_{*}$ along with a
generalized F prior on the heterogeneity $\tau^2$. Setting the heterogeneity to
$\tau^2 = 0$ under $\h{1}$ instead produces the replication Bayes factor under
normality from~\eqref{eq:bfr}.

The Bayes factor~\eqref{eq:bfalpha} that tests $\h{\text{d}}\colon \alpha = 0$ to
$\h{\text{c}}\colon \alpha = 1$ can be obtained in the hierarchical framework by
contrasting
\begin{align*}
  &\h{\text{d}}\colon \theta_{*} \sim \Nor(0, \kappa^{2})&
  &\text{versus}&
  &\h{\text{c}} \colon \theta_{*} \sim \Nor(s\,\that_{o}, s\,\sigma^{2}_{o})& \\
  &\phantom{\h{\text{d}}\colon} \tau^{2} = 0& &&
  &\phantom{\h{\text{c}}\colon} \tau^{2} = 0&
\end{align*}
with % shrinkage factor
$s = \kappa^{2}/(\sigma^2_o + \kappa^{2})$.
Hence, the Bayes factor compares the likelihood of the replication data under
the initial unit-information prior relative to the likelihood of the replication
data under the unit-information prior updated by the original data, assuming no
heterogeneity under either hypothesis (so that the hierarchical model collapses
to a fixed effects model). Although this particular test relates to the power
parameter $\alpha$ in the power prior model, it is surprisingly unrelated to
testing the heterogeneity variance $\tau^2$ in the hierarchical model.

The Bayes factor~\eqref{eq:bfdcrandom} testing
$\h{\text{d}}\colon \alpha < 1$ versus $\h{\text{c}}\colon \alpha = 1$
with $\alpha \given \h{\text{d}} \sim \Be(1, y)$
corresponds to testing $\h{\text{d}}\colon \tau^2 > 0$ versus $\h{\text{c}}\colon \tau^2 = 0$ with
\begin{align*}
  \theta_{*} \given \tau^{2}, \h{\text{d}} &\sim \Nor(\that_{o}, \sigma^{2}_{o} + \tau^{2})
%   f(\tau^{2}) = \Be\left\{\alpha = \sigma^{2}_{o}/(\sigma^{2}_{o} +
%     2\tau^{2})\given 1, y\right\}
%     (2\sigma^{2}_{o})/(2\tau^{2} + \sigma^{2}_o)^{2}
  % f\{\tau^{2} = (1/\alpha - 1)\, (\sigma^{2}_{o}/2)\}\{\sigma^{2}_{o}/(2\alpha^{2})\} &
  &\text{versus}& &
  \theta_{*} \given \tau^{2},\h{\text{c}} &\sim \Nor(\that_{o}, \sigma^{2}_{o} + \tau^{2}) \\
  \tau^2 \given \h{\text{d}}&\sim \mbox{GF}(y, 1, \sigma^2_o/2) &&&
  \h{\text{c}}\colon \tau^{2}&= 0
\end{align*}
The test for compatibility via the power parameter $\alpha$ is thus equivalent
to a test for compatibility via the heterogeneity $\tau^2$ (to which a
generalized F prior is assigned) after updating of a flat prior for $\theta_*$
with the data from the original study.

\subsection{Bayes factor asymptotics in the hierarchical model}

Like the original test of $\h{\text{c}}\colon \alpha = 1$ versus
$\h{\text{d}}\colon \alpha < 1$ with
$\alpha \given \h{\text{d}} \sim \Be(1, y)$, the corresponding test of $\tau^2$
is inconsistent in the sense that when the standard errors from both studies go
to zero ($\sigma_o \downarrow 0$ and $\sigma_r \downarrow 0$) and their true
effect sizes are equivalent ($\theta_o = \theta_r$), the Bayes factor
$\BF_{\text{dc}}$ does not go to zero (to indicate overwhelming evidence for
$\h{\text{c}}\colon \tau^2 = 0$) but converges to a positive constant.
It is, however, possible to construct a consistent test for
$\h{\text{c}}\colon \tau^2 = 0$ when we assign a different prior to $\tau^2$
under $\h{\text{d}}\colon \tau^2 > 0$. For instance, when we assign an inverse
gamma prior $\tau^2 \given \h{\text{d}} \sim \mbox{IG}(q, r)$ with shape $q$ and
scale $r$, the Bayes factor is given by
\begin{align*}
    \BF_{\text{dc}}(\that_r \given q, r)
    = \frac{\int \Nor(\that_r \given \that_o, \sigma^2_r + \sigma^2_o + 2\tau^2) \,
    \mbox{IG}(\tau^2 \given q, r) \, \text{d}\tau^2}{\Nor(\that_r \given \that_o,
    \sigma^2_r + \sigma^2_o)}
\end{align*}
with $\mbox{IG}(\cdot \given q, r)$ the density function of the inverse gamma
distribution. The limiting Bayes factor is therefore
\begin{align*}
    \lim_{\sigma_o, \sigma_r \downarrow 0} \BF_{\text{dc}}(\that_r \given q, r)
    = \frac{\Gamma(q + 1/2)\{r + (\theta_r - \theta_o)^2/4\}^{-(q + 1/2)}}{\delta(\theta_r - \theta_o) \, \sqrt{4\pi}},
\end{align*}
so it correctly goes to zero/infinity when the effect sizes $\theta_r$ and
$\theta_o$ are equivalent/different. To understand why the test with
$\tau^2 \given \h{\text{d}} \sim \mbox{IG}(q,r)$ is consistent, but the original
test with $\alpha \given \h{\text{d}} \sim \Be(1, y)$ is not, one can transform
the consistent test on $\tau^2$ to the corresponding test on $\alpha$. The
inverse gamma prior for $\tau^2$ implies a prior for $\alpha$ with density
\begin{align}
    \label{eq:igalpha}
    f(\alpha \given q, r)
    &= \frac{r^q}{\Gamma(q)} \, \frac{\alpha^{q - 1}}{(1 - \alpha)^{q + 1}} \,
    \left(\frac{2}{\sigma^2_o}\right)^{q} \,
    \exp\left\{-\frac{2 \,r\, \alpha}{\sigma^2_o(1 - \alpha)}\right\}.
\end{align}
The Bayes factor contrasting $\h{\text{c}}\colon \alpha = 1$ versus
$\h{\text{d}}\colon \alpha < 1$ with prior~\eqref{eq:igalpha} assigned to
$\alpha$ under $\h{\text{d}}$ will thus produce a consistent test. Importantly,
the prior~\eqref{eq:igalpha} depends on the variance of the original effect
estimate $\sigma^2_o$, so that original studies with different variances will
result in different priors on $\alpha$, even when the parameters $s$ and $t$
from the prior stay the same. The prior thus ``unscales'' $\alpha$ from the
original variance $\sigma^2_o$, thereby leading to a consistent test for study
compatibility and resolving the undesirable property of the beta prior.


\section{Discussion}
\label{sec:discussion}

We showed how the power prior framework can be used for design and analysis of
replication studies. The approach supplies analysts with a suite of methods for
assessing effect sizes and study compatibility. We also showed how the power
prior approach is connected to hierarchical modeling, and gave conditions under
which posterior distributions and hypothesis tests correspond between normal
power prior models and normal hierarchical models. This connection provides an
intuition for why even with highly precise and compatible original and
replication study one can hardly draw conclusive inferences about the power
parameter $\alpha$; the power parameter $\alpha$ has a direct correspondence to
the relative heterogeneity variance $I^2$, and an indirect correspondence to the
heterogeneity variance $\tau^2$ in a hierarchical model. Making inferences about
a heterogeneity variance from two studies alone seems like a virtually
impossible task since the ``unit of information'' is the number of studies and
not the number of samples within a study. Moreover, Bayes factor hypothesis
tests related to $\alpha$ have the undesirable asymptotic property of
inconsistency if a beta prior is assigned to $\alpha$. This is because the prior
scales with the variance of the original data, just as a beta prior for $I^2$
would in a hierarchical model.


Which of the two approaches should data analysts use in practice? We believe
that the choice should be primarily guided by whether the hierarchical or the
power prior model is \emph{scientifically} more suitable for the studies at
hand. If data analysts deem it scientifically plausible that the studies'
underlying effect sizes are connected via an overarching distribution then the
hierarchical model may be more suitable, particularly because the approach
naturally generalizes to more than two studies. On the other hand, if data
analysts simply want to downweight the original studies' contribution depending
on the observed conflict, the power prior approach might be more suitable. The
identified limitations for inferences related to the power parameter $\alpha$
should, however, be kept in mind when beta priors are assigned to the power
parameter $\alpha$.

There are also situations where the hierarchical and power prior frameworks can
be combined, for example, when multiple replications of a single original study
are conducted (multisite replications). In that case, one may model the
replication effect estimates in a hierarchical fashion but link their overall
effect size to the original study via a power prior. Multisite replications are
thus the opposite of the usual situation in clinical trials where several
historical ``original'' studies but only one current ``replication'' study is
available \citep{Gravestock2019}.

Another commonly used Bayesian approach for incorporating historical data are
\emph{robust mixture priors}, \ie{} priors which are mixtures of the posterior
based on the historical data and an uninformative prior distribution
\citep{Schmidli2014}. We conjecture that inferences based on robust mixture
priors can be reverse-engineered within the framework of power priors through
Bayesian model averaging over two hypotheses about the power parameter; however,
more research is needed to explore the relationship between the two approaches.

The proposed methods rely on the standard meta-analytic assumption of
approximate normality of effect estimates. This assumption might be inadequate
in some situations, for example, when studies have small sample sizes. In this
case, the methods could be modified to use the exact likelihood of the data
(\eg{} binomial or $t$). However, using the exact likelihood would require
numerical methods for the evaluation of integrals which can be evaluated
analytically under normality.

\section*{Software and data}
The CC-By Attribution 4.0 International licensed data were downloaded from
\url{https://osf.io/42ef9/}. All analyses were conducted in the R programming
language version \Sexpr{paste(version$major, version$minor, sep = ".")}
\citep{R}. The code and data to reproduce this manuscript is available at
\url{https://github.com/SamCH93/ppReplication}.
% A snapshot of the GitHub
% repository at the time of writing this article is archived at
% \url{https://doi.org/10.5281/zenodo.XXXXX}.
% TODO add once zenodo works
We also provide an R package for
estimation and testing under the power prior framework with documentation and
example code at \url{https://github.com/SamCH93/ppRep}.

\section*{Acknowledgments}
We thank \citet{Protzko2020} for publicly sharing their data. We thank
Magorzata Roos for helpful comments on a draft of the manuscript. This work was
supported in part by an NWO Vici grant (016.Vici.170.083) to EJW, an Advanced
ERC grant (743086 UNIFY) to EJW, and a Swiss National Science Foundation
mobility grant (189295) to LH and SP.
% Our acknowledgement of these individuals does not imply their endorsement of this article.


% \section*{Highlights}

% \textbf{What is already known?} \\
% The analysis of replication studies requires statistical models which can link
% the replication data to the original data, Bayesian hierarchical models have been
% used for that purpose. \\
% \textbf{What is new?} \\
% An alternative Bayesian power prior approach can be used for the same
% purpose. We show that there is a direct connection with
% hierarchical modeling in the sense that inferences under both approaches align if certain types of
% prior distributions are assigned to the power parameter (in the power prior model)
% and the between-study heterogeneity variance (in the hierarchical model), respectively. \\
% \textbf{Potential impact for readers?} \\
% The power prior framework supplies analysts with a suite of intuitive
% methods for assessing effect sizes and study compatibility in the replication
% setting. We give new theoretical insights and illustrate the methodology with
% a case study. We also provide an R package for performing these analyses.

% Appendix
% ------------------------------------------------------------------------------
\begin{appendices}
\section{Posterior distribution under the hierarchical model}
\label{app:postHierarch}

Under the hierarchical model from~\eqref{eq:hierarch-model}, the joint posterior
conditional on a heterogeneity $\tau^2$ is given by
\begin{align}
  \label{eq:jointpost2}
  f(\theta_{r}, \theta_{o}, \theta_{*} \given \that_{o}, \that_{r}, \tau^{2})
  = \frac{\prod_{i \in \{o, r\}} \Nor(\that_{i} \given \theta_{i}, \sigma^{2}_{i})
  \, \Nor(\theta_{i} \given \theta_{*}, \tau^{2}) \, k}{f(\that_{o}, \that_{r} \given \tau^2)}
\end{align}
with normalizing constant
\begin{align}
  f(\that_{o}, \that_{r} \given \tau^2)
  &= \int \prod_{i \in \{o, r\}} \Nor(\that_{i} \given \theta_i, \sigma^{2}_{i})
  \, \Nor(\theta_{i} \given \theta_{*}, \tau^{2}) \, k \,
  \text{d}\theta_o \,\text{d}\theta_r \,\text{d}\theta_* \nonumber \\
  &= \int \prod_{i \in \{o, r\}} \Nor(\that_{i} \given \theta_{*}, \sigma^{2}_{i} + \tau^2)
  k \, \text{d}\theta_* \nonumber \\
  &= k \, \Nor(\that_r \given \that_o, \sigma^{2}_{o} + \sigma^2_r + 2\tau^2).
  \label{eq:normConstHierarch}
\end{align}
To obtain the marginal posterior distribution of the replication effect size
$\theta_{r}$ we need to integrate out $\theta_{o}$ and $\theta_{*}$
from~\eqref{eq:jointpost2}. This leads to
\begin{align*}
  f(\theta_{r} \given \that_{o}, \that_{r}, \tau^{2})
  &= \frac{\int \prod_{i \in \{o, r\}} \Nor(\that_{i} \given \theta_{i}, \sigma^{2}_{i})
  \, \Nor(\theta_{i} \given \theta_{*}, \tau^{2}) \, k \,
  \text{d}\theta_o \,\text{d}\theta_*}{f(\that_{o}, \that_{r} \given \tau^2)} \\
  &= \frac{\Nor(\that_{r} \given \theta_{r}, \sigma^{2}_{r})
  \int \Nor(\theta_r \given \theta_{*}, \tau^2) \,
  \Nor(\that_{o} \given \theta_{*}, \sigma^{2}_{o} + \tau^2) \,
  \text{d}\theta_*}{\Nor(\that_r \given \that_o, \sigma^{2}_{o} + \sigma^2_r + 2\tau^2)} \\
  &= \frac{\Nor(\that_{r} \given \theta_{r}, \sigma^{2}_{r}) \,
  \Nor(\theta_r \given \that_o, \sigma^2_o + 2\tau^2)}{\Nor(\that_r \given \that_o, \sigma^{2}_{o} + \sigma^2_r + 2\tau^2)}
\end{align*}
which can be further simplified to identify the posterior given
in~\eqref{eq:posthierarch}.

When the heterogeneity $\tau^2$ is also assigned a prior distribution, the
posterior distribution can be factorized in the posterior conditional on
$\tau^2$ from~\eqref{eq:jointpost2} and the marginal posterior of $\tau^2$
\begin{align*}
  f(\tau^2, \theta_{r}, \theta_{o}, \theta_{*} \given \that_{o}, \that_{r})
  = f(\theta_{r}, \theta_{o}, \theta_{*} \given \that_{o}, \that_{r}, \tau^{2}) \,
  f(\tau^2 \given \that_{o}, \that_{r}).
\end{align*}
Integrating out $\theta_{r}, \theta_{o}$, and $\theta_{*}$ from the joint
posterior and using the previous results~\eqref{eq:normConstHierarch}, the
marginal posterior of $\tau^2$ can be derived to be
\begin{align*}
  f(\tau^2 \given \that_{o}, \that_{r})
  &= \frac{\int \prod_{i \in \{o, r\}} \Nor(\that_{i} \given \theta_{i}, \sigma^{2}_{i})
  \, \Nor(\theta_{i} \given \theta_{*}, \tau^{2}) \, k \, f(\tau^2) \,
  \text{d}\theta_o \,\text{d}\theta_r \,\text{d}\theta_*}{f(\that_o, \that_r)} \\
  &= \frac{f(\that_r, \that_o \given \tau^2)
  \, f(\tau^2)}{\int f(\that_r, \that_o \given \tau^2) \, f(\tau^2) \, \text{d}\tau^2} \\
  &= \frac{\Nor(\that_r \given \that_o, \sigma^{2}_{o} + \sigma^2_r + 2\tau^2)
  \, f(\tau^2)}{\int \Nor(\that_r \given \that_o, \sigma^{2}_{o} + \sigma^2_r + 2\tau^2) \, f(\tau^2) \, \text{d}\tau^2}.
\end{align*}

\section{Conditions for matching posteriors}
\label{app:mapping}

For the marginal posteriors of $\theta_r$ and $\theta$ to match it must hold for
every $\theta$ = $\theta_{r}$ that
\begin{align}
  f(\theta_r \given \that_{o}, \that_{r})
  &= f(\theta \given \that_{o}, \that_{r}) \nonumber \\
  \label{eq:margequal}
  \int_{0}^{\infty} f(\theta_{r} \given \that_{o}, \that_{r}, \tau^{2})\,
  f(\tau^{2} \given \that_{o}, \that_{r})\, \text{d} \tau^{2}
  &= \int_{0}^{1} f(\theta \given \that_{o}, \that_{r}, \alpha)\,
    f(\alpha \given \that_{o}, \that_{r}) \, \text{d} \alpha.
\end{align}
By applying a change of variables~\eqref{eq:tau2alpha} or~\eqref{eq:alpha2tau}
to the left or right hand side of \eqref{eq:margequal}, the marginal posteriors
conditional on $\tau^{2}$ and $\alpha$ match. It is now left to investigate
whether there are priors for $\tau^2$ and $\alpha$ so that also the marginal
posteriors of $\tau^{2}$ and $\alpha$ match. The marginal posterior distribution
of $\alpha$ is proportional to
\begin{align*}
  f(\alpha \given \that_{o}, \that_{r})
  \propto f_\alpha(\alpha) \,
  \Nor(\that_{r}\given \that_{o}, \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha).
\end{align*}
After a change of variables $\tau^{2} = (1/\alpha - 1)\,(\sigma^{2}_{o}/2)$ the
marginal posterior becomes
\begin{align*}
  f(\tau^{2} \given \that_{o}, \that_{r})
  \propto f_\alpha\left(\frac{\sigma^{2}_{o}}{2 \tau^{2} + \sigma^{2}_{o}}\right) \,
  \frac{2\sigma^{2}_{o}}{(2 \tau^{2} + \sigma^{2}_{o})^{2}} \,
  \Nor(\that_{r}\given \that_{o}, \sigma^{2}_{r} + \sigma^{2}_{o} + 2 \tau^{2}),
\end{align*}
Since, as shown in Appendix~\ref{app:postHierarch}, the marginal posterior of
$\tau^2$ under the hierarchical model is proportional to
\begin{align*}
  \label{eq:margposttau2}
  f(\tau^{2} \given \that_{o}, \that_{r})
  \propto
  f_{\tau^2}(\tau^{2}) \,
\Nor(\that_{r}\given \that_{o}, \sigma^{2}_{r} + \sigma^{2}_{o} + 2 \tau^{2}),
\end{align*}
% with
% $\widehat{V}(\tau^{2}) = 1/\{\sum_{i \in \{o, r\}} 1/(\tau^{2} + \sigma^{2}_{i})\}$
% and
% $\hat{\mu}(\tau^{2}) = \{\sum_{i \in \{o, r\}} \that_{i}/(\tau^{2} + \sigma^{2}_{i})\}
%     \widehat{V}(\tau^{2})$ \citep[chapter 5.4]{Gelman2013}.
the marginal posteriors of the effect sizes $\theta$ and $\theta_{r}$ match if
\begin{align*}
    f_{\tau^2}(\tau^{2}) = f_\alpha\left(\frac{\sigma^{2}_{o}}{2 \tau^{2} + \sigma^{2}_{o}}\right) \,
  \frac{2\sigma^{2}_{o}}{(2 \tau^{2} + \sigma^{2}_{o})^{2}}
\end{align*}
holds for every $\tau^{2}\geq 0$.

\section{The generalized beta and F distributions}
\label{app:distribution}

A random variable $X \sim \mbox{GBe}(a, b, \lambda)$ with density function
\begin{align}
    f(x\given a, b, \lambda)
    = \frac{\lambda^a \, x^{a - 1} \, (1 - x)^{b - 1}}{\mbox{B}(a, b) \,
    \{1 - (1 - \lambda)x\}^{a + b}} \, \mathbf{1}_{[0, 1]}(x)
\end{align}
follows a generalized beta distribution \citep[in the parametrization
of][]{Libby1982} with $\mathbf{1}_{S}(x)$ denoting the indicator function that
$x$ is in the set $S$. A random variable $X \sim \mbox{GF}(a, b, \lambda)$ with
density function
\begin{align}
    f(x\given a, b, \lambda)
    = \frac{\lambda^a \, x^{a - 1}}{\mbox{B}(a, b) \,
    (1 + \lambda x)^{a + b}} \, \mathbf{1}_{[0, \infty)}(x)
\end{align}
follows a generalized F distribution \citep[in the parametrization
of][]{PhamGia1989}.


\end{appendices}


% Bibliography
%% ------------------------------------------------------------------------------
\bibliographystyle{apalikedoiurl}
\bibliography{bibliography}


%% R sessionInfo for reproducibility
%% -----------------------------------------------------------------------------
<< "sessionInfo1", eval = Reproducibility, results = "asis" >>=
## print R sessionInfo to see system information and package versions
## used to compile the manuscript (set Reproducibility = FALSE, to not do that)
cat("\\newpage \\section*{Computational details}")
@
<< "sessionInfo2", echo = Reproducibility, results = Reproducibility >>=
sessionInfo()
@

\end{document}
