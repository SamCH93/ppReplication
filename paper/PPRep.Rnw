%% Template for a scientific paper by Samuel Pawel
%% Last modification: 17. December 2020
\documentclass[a4paper, 11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphics}
\usepackage[dvipsnames]{xcolor}
\usepackage{amsmath, amssymb}
\usepackage{doi} % automatic doi-links
\usepackage[round]{natbib} % bibliography
\usepackage{booktabs} % nicer tables
\usepackage[title]{appendix} % better appendices
\usepackage{nameref} % reference appendices with names
\usepackage{todonotes}


%% margins
%% ----------------------------------------------------------------------------
\usepackage{geometry}
\geometry{
  a4paper,
  total={170mm,257mm},
  left=25mm,
  right=25mm,
  top=20mm,
  bottom=20mm,
}

%% title, authors, affiliations, mail
%% ----------------------------------------------------------------------------
\newcommand\longtitle{Power priors for design and analysis of replication studies}
\newcommand\shorttitle{Power priors for replication studies} % if longtitle too long, change here
\newcommand\subtitle{}
\newcommand\longauthors{Samuel Pawel\textsuperscript{*}, Frederik Aust\textsuperscript{$\dagger$}, Eric-Jan Wagenmakers\textsuperscript{$\dagger$},
Leonhard Held\textsuperscript{*}}
\newcommand\shortauthors{S. Pawel, F. Aust, E.-J. Wagenmakers, L. Held} % if longauthors too long, change here
\newcommand\affiliation{
  * Department of Biostatistics, University of Zurich \\
  $\dagger$ Department of Psychological Methods, University of Amsterdam
}
\newcommand\mail{samuel.pawel@uzh.ch}
\title{
  \vspace{-2em}
  \textbf{\longtitle} \\
  \subtitle
}
\author{
  \textbf{\longauthors} \\
  \affiliation \\
  E-mail: \href{mailto:\mail}{\mail}
}
\date{\today} % don't forget to hard-code date when submitting to arXiv!

%% hyperref options
%% ----------------------------------------------------------------------------
\usepackage{hyperref}  
\hypersetup{
  bookmarksopen=true, 
  breaklinks=true,
  pdftitle={\shorttitle}, 
  pdfauthor={\shortauthors},
  pdfsubject={},
  pdfkeywords={},
  colorlinks=true,
  linkcolor=RoyalPurple,
  anchorcolor=black,
  citecolor=MidnightBlue,
  urlcolor=black,
}

%% Headers and footers
%% ----------------------------------------------------------------------------
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{\shorttitle}
\rhead{\shortauthors}

%% custom commands
%% ----------------------------------------------------------------------------
\input{defs.tex}

\begin{document}
\maketitle

%% Disclaimer that a preprint
\begin{center}
  {\color{red}This is a preprint which has not yet been peer reviewed.}
\end{center}

% knitr options
% -----------------------------------------------------------------------------
<< "main-setup", include = FALSE >>=
library(knitr)
opts_chunk$set(fig.height = 4,
               echo = FALSE,
               warning = FALSE,
               message = FALSE,
               cache = FALSE,
               eval = TRUE)
@

%% Abstract
%% -----------------------------------------------------------------------------
\begin{center}
  \begin{minipage}{13cm} {\small
      \rule{\textwidth}{0.5pt} \\
      {\centering \textbf{Abstract} \\
        Power priors are a class of prior distributions that allow to
        incorporate historical data in Bayesian analyses. One domain where
        historical data are available is the analysis of replication studies.
        Despite the growing interest in replication studies, no one has yet
        investigated a power prior modeling approach for the analysis of
        replication studies. Here, we explore this idea for both parameter
        estimation and hypothesis testing. We show how power priors help both in
        estimation and testing of effect sizes via a dynamic borrowing of
        information from the original study. At the same time, they allow to
        make inferences about study compatibility through the power parameter,
        which links the original to the replication study. It is well known that
        for normal data there is an exact mapping of posterior inferences
        between power prior and hierarchical models when the power parameter and
        heterogeneity variance are fixed. We establish that a similar mapping
        exists also in the case when these parameters are assigned a prior
        distribution. Our results help to better understand prior distributions
        on heterogenetiy variances, and also how power prior models can
        alternatively be estimated through a hierarchical modeling framework.
      } \\
      \rule{\textwidth}{0.5pt} \emph{Key words}: Power prior, hierarchical
      models, replication studies, historical data, Bayesian hypothesis testing,
      Bayesian parameter estimation}
\end{minipage}
\end{center}


\section{Introduction}

Power priors are a useful class of informative prior distributions that allow to
incorporate historical data in Bayesian analyses \citep{Ibrahim2015}. The most
basic version of the power prior is obtained by updating an initial prior with
the likelihood of the historical data raised to the power of $\alpha$, where
$\alpha$ is usually restricted to the range between zero and one. As such, the
power parameter $\alpha$ specifies how much the historical data are discounted,
and thus provides a quantitative and easy to interpret way of incorporating
historical data.


One domain where historical data are available is the analysis of replication
studies. The question is typically to what extent the replication study
replicated the result of an original study. Several methods have been proposed
to answer this question \citep[among others]{Bayarri2002, Verhagen2014,
  Johnson2016, Etz2016, vanAert2017, Ly2018, Hedges2019, Mathur2020, Held2020,
  Pawel2020, Pawel2020b, Held2021}. Constructing a power prior from the original
data and using it in the analysis of the replication study seems a natural thing
to do. However, no one has yet investigated such an approach.

In this paper we show how power priors can be constructed from data of an
original study under a meta-analytic framework (Section~\ref{sec:power-prior}).
We then show, how the power prior can then be used for for both parameter
estimation (Section~\ref{sec:parameter-estimation}) and hypothesis testing
(Section~\ref{sec:hypothesis-testing}). Our results indicate that power priors
help both in estimation and testing of effect sizes via a dynamic borrowing of
information from the original study. At the same time, the approach enables
inferences about study compatibility through the power parameter, which links
the original to the replication study. It is well known that for normal data
there is an exact mapping of posterior inferences between power prior and
hierarchical models when the power parameter and heterogeneity variance are
fixed \citep{Chen2006}. We establish that a similar mapping exists also in the
case when these parameters are random and assigned a prior distribution \dots

\section{The power prior based on an original study}
\label{sec:power-prior}
Let $\theta$ denote an unknown effect size and $\that_{i}$ an estimate thereof
obtained from study $i \in \{o, r\}$ where the subscript indicates ``original''
or ``replication'', respectively. Assume that the likelihood of the effect
estimates can be approximated by a normal distribution
\begin{align*}
  \that_{i} \given \theta \sim \Nor(\theta, \sigma^{2}_{i})
\end{align*}
with $\sigma_{i}$ the (assumed to be known) standard error of the effect
estimate $\that_{i}$. This is the same framework as typically used in
meta-analysis, and it is applicable to many types of data and effect sizes
\citep[chapter 2.4]{Spiegelhalter2004}. There are, of course, situations where
the approximation is inadequate and modified distributional assumptions are
required (\eg for data from studies with small sample sizes and/or extreme
effect sizes).

The goal is now to construct a power prior for $\theta$ based on the data from
the original study. % Assume an initial prior distribution for the effect size
% \begin{align*}
%   \theta \sim \Nor(m_{0}, v_{0}),
    %   \end{align*}
Under an (improper) flat initial prior $f(\theta) \propto 1$, normalization of
the likelihood of the original data raised to a (fixed) power parameter $\alpha$
leads to the normalized power prior
\begin{align}
  \theta \given \that_{o}, \sigma_{o}, \alpha
  \sim \Nor\left(\that_{o}, \frac{\sigma^{2}_{o}}{\alpha}\right)
  \label{eq:pp}
\end{align}
as proposed by \citet{Neuenschwander2009}. There are different ways to specify
$\alpha$. The simplest approach fixes $\alpha$ to an a priori reasonable value,
possibly informed from external knowledge about the similarity of the two
studies. Another option is to use the empirical Bayes estimate
\citep{Gravestock2017}, that is, the value of $\alpha$ that maximizes the
likelihood of the replication data marginalized over the power prior
\begin{align*}
  \hat{\alpha}_{\text{EB}}
  = \max\left[0, \min\left\{1, \frac{\sigma^{2}_{o}}{(\that_{o} - \that_{r})^{2}
  - \sigma^{2}_{r}}\right\}\right].
\end{align*}
Finally, it is also possible to specify a prior distribution for $\alpha$, the
most common choice being a marginal beta distribution
\begin{align*}
  \alpha \given x, y \sim \Be(x, y)
\end{align*}
for a normalized power prior conditional on $\alpha$ as in~\eqref{eq:pp}. The
uniform distribution ($x = 1$, $y = 1$) is often recommended as the default
choice in the literature \citep{Ibrahim2015}. % However, we note that if $\alpha$
% is not restricted to the unit interval, another default choice could be a
% $f(\alpha) \propto \alpha^{-1}$ as this is the reference prior for a precision
% parameter in the normal model.
% In order for the joint prior of $\alpha$ and $\theta$ to be a valid propability
% distribution, their product must be appropriately normalized
% \begin{align*}
%   f(\theta, \alpha \given \that_{o}, \sigma_{o}, x, y)
%   =
% \end{align*}

% The parameter $\alpha$ provides a link between the original and replication
% study. So if the objective is to make inferences about the compatibility of the
% study results, considering $\alpha$ as random seems the most useful choice. With
% this approach one can then compute a posterior distribution of $\alpha$ based on
% the data from both studies.

\section{Parameter estimation}
\label{sec:parameter-estimation}
<< "posterior-distribution" >>=
## functoin to format BF
.formatBF_ <- function(BF, digits = "default") {
    ## check inputs
    stopifnot(
        length(BF) == 1,
        is.numeric(BF),
        (is.finite(BF) && 0 < BF) || is.na(BF),

        length(digits) == 1,
        (is.character(digits) && digits == "default") ||
        (is.numeric(digits) && 0 <= digits)
    )
    ## return NA if input NA/nan
    if (is.na(BF) || is.nan(BF))
        result <- NA
    else {
        ## format BF
        if (digits == "default") {
            if (BF < 1/1000)
                result <- "< 1/1000"
            if ((BF >= 1/1000) & (BF <= 1/10))
                result <- paste0("1/", as.character(round(1/BF)))
            if ((BF > 1/10) & (BF < 1))
                result <- paste0("1/", as.character(round(1/BF, digits = 1)))
            if ((BF < 10) & (BF >= 1))
                result <- as.character(round(BF, digits = 1))
            if ((BF >= 10) & (BF <= 1000))
                result <- as.character(round(BF))
            if (BF > 1000)
                result <- "> 1000"
        } else {
            if (BF < 1)
                result <- paste0("1/", as.character(round(1/BF, digits = digits)))
            else
                result <- as.character(round(BF, digits = digits))
        }
        ## when 1/1 return 1
        if (result == "1/1") result <- "1"
    }
    return(result)
}
formatBF <- Vectorize(FUN = .formatBF_)

## functions are now in pkg
library(ppRep)
@

% asdsad

Assuming a beta prior for $\alpha$ and conditioning on the replication data
leads to the posterior distribution
\begin{align}
  f(\alpha, \theta \given \that_{r}, \that_{o}, \sigma_{o}, \sigma_{r}, x, y)
  =& \frac{\Nor(\that_{r}; \theta, \sigma^{2}_{r}) \times
     \Nor(\theta; \that_{o}, \sigma^{2}_{o}/\alpha) \times \Be(\alpha; x, y)}{
     f(\that_{r} \given \that_{o}, \sigma_{r}, \sigma_{o}, x, y)}
     \label{eq:posterior} \\
  \propto& \exp\left[-\frac{1}{2} \left\{
           \left(\frac{1}{\sigma^{2}_{r}} + \frac{\alpha}{\sigma^{2}_{o}}\right)
           \left(\theta - \frac{\that_{r}/\sigma^{2}_{r} + (\that_{r}\, \alpha) / \sigma^{2}_{o}}{
           1/\sigma^{2}_{r} + \alpha/\sigma^{2}_{o}}\right)^{2} +
           \frac{(\that_{o} - \that_{r})^{2}}{\sigma^{2}_{o}/\alpha + \sigma^{2}_{r}}
           \right\}\right]  \nonumber \\
   & \times \alpha^{x - 1/2} \, (1 - \alpha)^{y - 1} \nonumber
\end{align}
with $\Nor(z; m, v)$ the density function of a normal distribution with mean $m$
and variance $v$ evaluated at $z$, and $\Be(u; q, p)$ the density function of a
beta distribution with parameters $q$ and $p$ evaluated at $u$. The normalizing
constant
\begin{align*}
  f(\that_{r} \given \that_{o}, \sigma_{r}, \sigma_{o}, x, y)
  &= \int_{0}^{1} \int_{-\infty}^{\infty} \Nor(\that_{r}; \theta, \sigma^{2}_{r}) \times
  \Nor(\theta; \that_{o}, \sigma^{2}_{o}/\alpha) \times \Be(\alpha; x, y) \,
  \text{d}\theta \, \text{d}\alpha \\
  &= \int_{0}^{1}  \Nor(\that_{r}; \that_{o},  \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha)
  \times \Be(\alpha; x, y) \, \text{d}\alpha
\end{align*}
is not available in closed form but requires numerical integration with respect
to the prior distribution of $\alpha$. Finally, if inference concerns only one
parameter, a marginal posterior distributions for either $\alpha$ or $\theta$
can be obtained by integrating out the respective nuisance parameter
from~\eqref{eq:posterior}. In the case of the power parameter $\alpha$, this leads to
\begin{align}
   f(\alpha, \given \that_{r}, \that_{o}, \sigma_{o}, \sigma_{r}, x, y)
  =& \frac{\Nor(\that_{r}; \that_{o}, \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha) \times
     \Be(\alpha; x, y)}{f(\that_{r} \given \that_{o}, \sigma_{r}, \sigma_{o}, x, y)}
     \label{eq:margalpha}
\end{align}
while for the effect size $\theta$, we have
\begin{align*}
  f(\theta, \given \that_{r}, \that_{o}, \sigma_{o}, \sigma_{r}, x, y)
  =& \frac{\Nor(\that_{r}; \theta, \sigma^{2}_{r})  \int_{0}^{1}
     \Nor(\theta; \that_{o}, \sigma^{2}_{o}/\alpha) \times \Be(\alpha; x, y)
     \, \text{d}\alpha}{f(\that_{r} \given \that_{o}, \sigma_{r}, \sigma_{o}, x, y)}.
\end{align*}


<< "example-posterior" >>=
## TODO find better / real example
data(protzko2020, package = "ReplicationSuccess")
ex <- "Labels"
dat <- subset(protzko2020, experiment == ex)
to <- dat$smd[dat$type == "original"]
to <- to + .Machine$double.eps ## add a tiny amount so that correctly rounded (because 0.205)
no <- dat$n[dat$type == "original"]
tr <- dat$smd[dat$type == "external-replication"]
tr[3] <- tr[3] + .Machine$double.eps ## add a tiny amount so that correctly rounded (because 0.205)
so <- dat$se[dat$type == "original"]
sr <- dat$se[dat$type == "external-replication"]
nr <- dat$n[dat$type == "external-replication"]
rnumber <- c(1, 3, 2)

## uniform prior for alpha
x <- 1
y <- 1
@

\subsection{Example ``\Sexpr{ex}''}
We will now apply the methodology to data from a large-scale replication project
by \citet{Protzko2020}. The project featured an experiment called ``\Sexpr{ex}''
for which the original study found the following result: ``When a researcher
uses a label to describe people who hold a certain opinion, he or she is
interpreted as disagreeing with those attributes when a negative label is used
and agreeing with those attributes when a positive label is used.'' This finding
came with a standardized mean difference effect estimate
$\that_{o} = \Sexpr{round(to, 2)}$ and standard error
$\sigma_{o} = \Sexpr{round(so, 2)}$ obtained from $\Sexpr{round(no, 1)}$
participants. Subsequently, four replication studies were conducted, three of
them by a different lab than the original one, and all employing large sample
sizes.


\begin{figure}[!htb]
<< "fig-example-posterior", fig.height = 6 >>=
## grid for posterior
nalpha <- 200
ntheta <- 200
alphaseq <- seq(0, 1, length.out = nalpha)
thetaseq <- seq(0, 0.6, length.out = ntheta)
parGrid <- expand.grid(alpha = alphaseq, theta = thetaseq)

## compute joint posterior
jointplotDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    pDens <- postPP(theta = parGrid$theta, alpha = parGrid$alpha, tr = tr[i],
                    sr = sr[i], to = to, so = so, x = x, y = y)
    parGrid$density <- pDens
    parGrid$tr <- tr[i]
    parGrid$sr <- sr[i]
    parGrid$rnumber <- rnumber[i]
    return(parGrid)
}))
jointplotDF$trFormat <- paste0("{hat(theta)[italic('r')*", jointplotDF$rnumber,
                               "] == ", round(jointplotDF$tr, 2),
                               "}*',' ~ sigma[italic('r')*", jointplotDF$rnumber,
                               "] == ", round(jointplotDF$sr, 2))

## plot posterior
library(ggplot2)
library(colorspace)
plotTop <- ggplot(data = jointplotDF, aes(x = theta, y = alpha, fill = density)) +
    facet_wrap(~ trFormat,
               labeller = label_parsed) +
    geom_raster() +
    scale_fill_continuous_sequential(palette = "Blues 3", rev = TRUE) +
    labs(x = bquote("Effect size" ~ theta),
         y = bquote("Power parameter" ~ alpha),
         fill = "Posterior \ndensity") +
    guides(fill = guide_colorbar(barheight = 10, barwidth = 0.5)) +
    theme_minimal() +
    theme(panel.grid.minor = element_blank())


## compute marginal posteriors
alphaplotDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    pDens <- postPPalpha(alpha = alphaseq, tr = tr[i], sr = sr[i], to = to,
                         so = so, x = x, y = y)
    out <- data.frame(x = alphaseq, density = pDens, rnumber = rnumber[i],
                      parameter = "'Power parameter' ~ alpha", tr = tr[i], sr = sr[i])
    return(out)
}))
thetaplotDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    pDens <- postPPtheta(theta = thetaseq, tr = tr[i], sr = sr[i], to = to,
                         so = so, x = x, y = y)
    out <- data.frame(x = thetaseq, density = pDens, rnumber = rnumber[i],
                      parameter = "'Effect size' ~ theta", tr = tr[i], sr = sr[i])
    return(out)
}))
margplotDF <- rbind(alphaplotDF, thetaplotDF)
margplotDF$trFormat <- paste0("{hat(theta)[italic('r')*", margplotDF$rnumber,
                              "] == ", round(margplotDF$tr, 2),
                              "}*',' ~ sigma[italic('r')*", margplotDF$rnumber,
                              "] == ", round(margplotDF$sr, 2))

## plot marginals
plotBot <- ggplot(data = margplotDF, aes(x = x, y = density, color = trFormat)) +
    facet_wrap(~ parameter, scales = "free", labeller = label_parsed,
               strip.position = "bottom") +
    geom_line(alpha = 0.9) +
    theme_bw() +
    labs(x = NULL, y = "Marginal posterior density", color = "") +
    scale_color_discrete_qualitative(palette = "Dark 3", labels = scales::parse_format()) +
    theme(legend.position = "top", panel.grid.minor = element_blank(),
          strip.background.x = element_blank(), strip.placement = "outside",
          legend.text.align = 0)

ggpubr::ggarrange(plotTop, plotBot, ncol = 1, heights = c(0.5, 0.5))
@
\caption{Bayesian analysis of three replication studies from the replication
  project by \citet{Protzko2020}. Shown are joint (top) and marginal (bottom)
  posterior distributions of effect size $\theta$ and power parameter $\alpha$.
  A power prior for the effect size $\theta$ is constructed from the original
  effect estimate $\that_{o} = \Sexpr{round(to, 2)}$ (with standard error
  $\sigma_{o} = \Sexpr{round(so, 2)}$) and an initial flat prior
  $f(\theta) \propto 1$. A
  $\alpha \sim \Be(\Sexpr{round(x, 2)}, \Sexpr{round(y, 2)})$ marginal prior
  distribution is used for the power parameter.}
\label{fig:post2d}
\end{figure}

Figure~\ref{fig:post2d} shows joint and marginal posterior distributions for
effect size $\theta$ and power parameter $\alpha$ based on the results of the
three external replication studies. % The data from the original data is used to
% construct a power prior for the unknown standardized mean difference effect size
% $\theta$ along with a uniform prior for the power parameter
% $\alpha \sim \Be(1, 1)$.
We see that one replication found a virtually identical effect estimate as the
original study ($\that_{r} = \Sexpr{round(tr[3], 2)}$), while the other two
replications found either a smaller or larger effect estimate
($\that_{r} = \Sexpr{round(tr[1], 2)}$ and
$\that_{r} = \Sexpr{round(tr[2], 2)}$). This is reflected in the marginal
posterior distributions of the power parameter $\alpha$. That is, the marginal
distribution of replication with the very conflicting effect estimate is sharply
peaked and has most mass at small values of $\alpha$. In contrast, the marginal
distribution based on the replication with strongly agreeing effect estimate is
monotonically increasing, giving the highest support to the value $\alpha = 1$.
Yet, the posterior density at $\alpha = 1$ is not much higher than one (the
density of prior), suggesting that it is difficult to obtain conclusive
posterior inferences about $\alpha$, even from two highly precise studies.


The marginal distribution of the effect size $\theta$ shows that the degree of
compatibility between the two studies, influences how much information is
borrowed from the original study. For instance, the marginal posterior density
based on the most compatible replication
($\that_{r} = \Sexpr{round(tr[3], 2)}$), is the most concentrated among the
three replications, despite that this estimate was the least precise. In
contrast, the marginal posterior of the most conflicting estimate
($\that_{r} = \Sexpr{round(tr[2], 2)}$) borrows fewer information and is the
least peaked posterior, despite being the most precise estimate among the three.


\subsection{Connection to parameter estimation hierarchical models}
Hierarchical modeling is another approach that allows for incorporation of
historical data, and hierarchical models have also been used in the replication
setting previously \citep{Bayarri2002, Pawel2020}. Assume a hierarchical model
\begin{subequations}
\label{eq:hierarch-model}
\begin{align*}
  \that_{i} \given \theta_{i}\, &\sim \Nor(\theta_{i}, \sigma^{2}_{i}) \\
  \theta_{i} \given \theta_{*} &\sim \Nor(\theta_{*}, \tau^{2}) \\
  \theta_{*} &\sim \Nor(0, \infty)
\end{align*}
\end{subequations}
for study $i \in \{o ,r\}$.
% Conditional on the heterogeneity variance $\tau^{2}$, t
The joint posterior is then proportional to
\begin{align}
  \label{eq:jointpost}
  f(\theta_{r}, \theta_{o}, \theta_{*} \given \that_{o}, \that_{r}, \tau^{2})
  \propto \prod_{i \in \{o, r\}} \Nor(\that_{i}; \theta_{i}, \sigma^{2}_{i})
  \, \Nor(\theta_{i}; \theta_{*}, \tau^{2}).
\end{align}
By integrating out $\theta_{o}$ and $\theta_{*}$ from~\eqref{eq:jointpost}, one
can show that the marginal posterior distribution of the replication effect size
$\theta_{r}$ is
\begin{align}
  \label{eq:posthierarch}
  \theta_{r} \given \that_{o}, \that_{r}, \tau^{2}
  \sim \Nor\left(\frac{\that_{r}/\sigma^{2}_{r} + \that_{o}/(2\tau^{2} +
  \sigma^{2}_{o})}{1/\sigma^{2}_{r} + 1/(2\tau^{2} + \sigma^{2}_{o})},
  \frac{1}{1/\sigma^{2}_{r} + 1/(2\tau^{2} + \sigma^{2}_{o})}\right).
\end{align}

The question is now whether there is a correspondence between the hierarchical
and the power prior approach. Under the power prior and for a fixed power
parameter $\alpha$, the posterior of the effect size $\theta$
from~\eqref{eq:posterior} simplifies to a normal
\begin{align}
  \label{eq:postpower}
  \theta \given \that_{o}, \that_{r}, \alpha
  \sim \Nor\left(\frac{\that_{r}/\sigma^{2}_{r} +
  (\that_{o}\alpha)/\sigma^{2}_{o}}{1/\sigma^{2}_{r} + \alpha/\sigma^{2}_{o}},
  \frac{1}{1/\sigma^{2}_{r} + \alpha/\sigma^{2}_{o}}\right).
\end{align}
Theorem 2.2 in \citet{Chen2006} establishes that the two posterior
distributions~\eqref{eq:posthierarch} and~\eqref{eq:postpower} match if and only
if
\begin{align*}
  \alpha = \frac{\sigma^{2}_{o}}{2\tau^{2} + \sigma^{2}_{o}},
  % &\text{respectively}&
  % &\tau^{2} = \left(\frac{1}{\alpha} - 1\right) \,
  %   \frac{\sigma^{2}_{o}}{2}
\end{align*}
respectively
\begin{align*}
  \tau^{2} = \left(\frac{1}{\alpha} - 1\right) \, \frac{\sigma^{2}_{o}}{2}.
\end{align*}
For instance, a power prior model with $\alpha = 1$ corresponds to a
hierarchical model with $\tau^{2} = 0$, and a hierarchical model with
$\tau \to \infty$ corresponds to a power prior model with $\alpha \downarrow 0$.
% it follows from Theorem 2.2 in \citet{Chen2006} that the posterior distribution
% of the replication effect size
% $f(\theta_{r} \given \that_{o}, \that_{r}, \sigma_{o}, \sigma_{r}, \tau^{2})$
% matches with the posterior distribution of the effect size based on the (fixed
% $\alpha$) power prior
% $f(\theta \given \that_{o}, \that_{r}, \sigma_{o}, \sigma_{r}, \alpha)$ if and
% only if
% \begin{align*}
%   \alpha = \frac{\sigma^{2}_{o}}{2\tau^{2} + \sigma^{2}_{o}}.
% \end{align*}
% This means that in the case of fixed power parameters $\alpha$ , respectively,
% between-study heterogeneity variances $\tau^{2}$, there is an exact
%       correspondence of the two approaches.
Interestingly, there is a direct mapping from $\alpha$ to the popular relative
heterogeneity measure $I^{2} = \tau^{2}/(\tau^{2} + \sigma^{2}_{o})$
\citep{Higgins2002}, that is
\begin{align*}
  \alpha = \frac{1 - I^{2}}{1 + I^{2}},
\end{align*}
see also Figure~\ref{fig:I2}. We see that there is an almost linear relationship
betwen the two. A useful heuristic to connect power priors to hierarchical
models is thus $\alpha \approx 1 - I^{2}$.

\begin{figure}[!htb]
<< "I2plot", fig.height = 3 >>=
## show relationship between I^2 and alpha
I2seq <- seq(from = 0, to = 1, length.out = 500)
alphaseq <- (1 - I2seq)/(1 + I2seq)
plotDF <- data.frame(I2 = I2seq, alpha = alphaseq, tau2 = so^2/2*(1/alphaseq - 1))
ggplot(data = plotDF, aes(x = I2, y = alpha)) +
    geom_line() +
    labs(x = bquote(I^2), ## bquote(I^2 == frac(tau^2, tau^2 + sigma["o"]^2)),
         y = bquote(alpha)) +
    coord_fixed() +
    theme_bw() +
    theme(panel.grid.minor = element_blank())
@
\caption{Relative heterogeneity $I^{2} = \tau^{2}/(\tau^{2} + \sigma^{2}_{o})$
  of hierarchical model and power parameter $\alpha$ from power prior model
  which lead to matching posteriors for the effect sizes $\theta$ and
  $\theta_{r}$.}
\label{fig:I2}
\end{figure}

It is unclear whether a mapping exists in cases where $\alpha$ and $\tau^{2}$
are random. If it would exist, it must hold for any $\theta$ = $\theta_{r}$ that
\begin{align}
  \label{eq:margequal}
  \int_{0}^{\infty} f(\theta_{r} \given \that_{o}, \that_{r}, \tau^{2})\,
  f(\tau^{2} \given \that_{o}, \that_{r})\, \text{d} \tau^{2}
  &= \int_{0}^{1} f(\theta \given \that_{o}, \that_{r}, \alpha)\,
    f(\alpha \given \that_{o}, \that_{r}) \, \text{d} \alpha.
  % &=
  %   \int_{0}^{\infty} f(\theta \given \that_{o}, \that_{r}, \alpha(\tau^{2}_{*}))\,
  % f(\alpha(\tau^{2}_{*}) \given \that_{o}, \that_{r}) \,
  % \frac{2\sigma^{2}_{o}}{(2 \tau^{2}_{*} + \sigma^{2}_{o})^{2}} \,
  % \text{d} \tau^{2}_{*} \\
\end{align}
By applying a change of variables to the left or right hand side of
\eqref{eq:margequal}, the marginal posteriors conditional on $\tau^{2}$ and
$\alpha$ match. It is now left to investigate whether there are priors
$f(\tau^{2})$ and $f(\alpha)$ so that also the marginal posteriors of $\tau^{2}$
and $\alpha$ match. By replacing the beta prior in~\eqref{eq:margalpha} with an
unspecified prior $f(\alpha)$, we can see that the marginal posterior
distribution of $\alpha$ is proportional to
\begin{align*}
  f(\alpha \given \that_{o}, \that_{r})
  \propto f(\alpha) \times
  \Nor(\that_{r}; \that_{o}, \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha).
\end{align*}
After a change of variables $\tau^{2}_{*} = (1/\alpha - 1)\,(\sigma^{2}_{o}/2)$ this
becomes
\begin{align*}
  f(\tau^{2}_{*} \given \that_{o}, \that_{r})
  \propto f\left(\alpha = \frac{\sigma^{2}_{o}}{2 \tau^{2}_{*} + \sigma^{2}_{o}}\right) \,
  \frac{2\sigma^{2}_{o}}{(2 \tau^{2}_{*} + \sigma^{2}_{o})^{2}} \times
  (\sigma^{2}_{o} + \sigma^{2}_{r} +  2\tau^{2}_{*})^{-1/2} \,
  % \Nor(\that_{r}; \that_{o}, \sigma^{2}_{r} + \sigma^{2}_{o} + 2 \tau^{2}_{*}).
  \exp\left\{
  - \frac{1}{2} \frac{(\that_{r} - \that_{o})^{2}}{\sigma^{2}_{o} +
  \sigma^{2}_{r} + 2 \tau^{2}_{*}}\right\}.
\end{align*}
By integrating out $\theta_{r}, \theta_{o}$, and $\theta_{*}$ from the joint
posterior under the hierarchical model, one can show that the marginal
posterior of the heterogeneity variance $\tau^{2}$ is proportional to
\begin{align*}
  f(\tau^{2} \given \that_{o}, \that_{r})
  % \propto
  % f(\tau^{2}) \times
  % \prod_{i\in \{o, r\}} \Nor(\that_{i}; \hat{\mu}(\tau^{2}), \sigma^{2}_{i} + \tau^{2})
  % \big / \Nor(\hat{\mu}(\tau^{2}); \hat{\mu}(\tau^{2}), \widehat{V}(\tau^{2}))
  \propto
  f(\tau^{2}) \times
  (\sigma^{2}_{o} + \sigma^{2}_{r} +  2\tau^{2})^{-1/2} \, \exp\left\{
  - \frac{1}{2} \frac{(\that_{r} - \that_{o})^{2}}{\sigma^{2}_{o} +
  \sigma^{2}_{r} + 2 \tau^{2}}\right\}.
\end{align*}
% with
% $\widehat{V}(\tau^{2}) = 1/\{\sum_{i \in \{o, r\}} 1/(\tau^{2} + \sigma^{2}_{i})\}$
% and
% $\hat{\mu}(\tau^{2}) = \{\sum_{i \in \{o, r\}} \that_{i}/(\tau^{2} + \sigma^{2}_{i})\}
%     \widehat{V}(\tau^{2})$ \citep[chapter 5.4]{Gelman2013}.
This implies that the marginal posteriors of the effect sizes $\theta$ and
$\theta_{r}$ match if it holds for every $\tau^{2} = \tau^{2}_{*}$ that
\begin{align}
  \label{eq:matchCond}
  f(\tau^{2}) = f\left(\alpha = \frac{\sigma^{2}_{o}}{2 \tau^{2}_{*} + \sigma^{2}_{o}}\right) \,
  \frac{2\sigma^{2}_{o}}{(2 \tau^{2}_{*} + \sigma^{2}_{o})^{2}}.
\end{align}
For example, if we assign a $\Be(x, y)$ prior to $\alpha$, the posteriors will
match for a
\begin{align*}
  f(\tau^{2}) \propto
  \left(\frac{2\tau^{2}}{\sigma^{2}_{o}} + 1\right)^{1 - x}
  \left(\frac{\sigma^{2}_{o}}{2\tau^{2}} + 1\right)^{1 - y}
  \frac{2\sigma^{2}_{o}}{(2 \tau^{2} + \sigma^{2}_{o})^{2}}
\end{align*}
prior on $\tau^{2}$. Similarly, we could do a change of variables from
$\tau^{2}$ to $\alpha_{*} = \sigma^{2}_{o}/(2\tau^{2} + \sigma^{2}_{o})$ and
see that the posteriors match if we assing a
\begin{align}
  \label{eq:matchCond2}
  f(\alpha) = f\left\{\tau^{2} = \left(\frac{1}{\alpha_{*}} - 1\right) \frac{\sigma^{2}_{o}}{2}
  \right\} \,
  \frac{\sigma^{2}_{o}}{2\alpha^{2}_{*}}
\end{align}
prior to $\tau^{2}$.
\begin{figure}[!htb]
<< "corresponding-priors", fig.height = 5 >>=
## corresponding heterogeneity variance priors for alpha ~ Beta(a, b)
ftau2 <- function(tau2, a, b, so) {
    dbeta(x = so^2/(2*tau2 + so^2), shape1 = a, shape2 = b) *
        2*so^2/(2*tau2 + so^2)^2
}

## compute priors for a grid of Beta priors
paramsGrid <- data.frame(a = c(1, 2, 1),
                         b = c(1, 1, 2))
aseq <- seq(0, 1, length.out = 500)
tau2seq <- seq(0, 0.1, length.out = 500)^2
alphaDF <- do.call("rbind", lapply(X = seq(1, nrow(paramsGrid)), FUN = function(i) {
    a <- paramsGrid$a[i]
    b <- paramsGrid$b[i]
    dens <- dbeta(x = aseq, shape1 = a, shape = b)
    out <- data.frame(x = aseq, xlab = "alpha", density = dens, a = a, b = b,
                      ylab = paste0("{italic(x) ==", a, "}*','~ italic(y) ==", b))
    return(out)
}))
tau2DF <- do.call("rbind", lapply(X = seq(1, nrow(paramsGrid)), FUN = function(i) {
    a <- paramsGrid$a[i]
    b <- paramsGrid$b[i]
    dens <- ftau2(tau2 = tau2seq, a = a, b = b, so = so)
    out <- data.frame(x = tau2seq, xlab = "tau^2", density = dens, a = a, b = b,
                      ylab = paste0("{italic(x) ==", a, "}*','~ italic(y) ==", b))
    return(out)
}))
plotDF <- rbind(alphaDF, tau2DF)
alphaDF$ylabFac <- factor(x = alphaDF$ylab, levels = unique(plotDF$ylab))
tau2DF$ylabFac <- factor(x = tau2DF$ylab, levels = unique(plotDF$ylab))

## plot beta priors for alpha and corresponding priors for tau^2
plotalpha <- ggplot(data = alphaDF, aes(x = x, y = density)) +
    facet_grid(ylabFac ~ ., labeller = label_parsed, scales = "free",
               switch = "x") +
    geom_line() +
    labs(x = bquote(alpha), y = NULL) +
    expand_limits(y = c(0, 3)) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(),
          strip.background.x = element_blank(), strip.placement = "outside")

plottau <- ggplot(data = tau2DF, aes(x = x, y = density)) +
    facet_grid(ylabFac ~ ., labeller = label_parsed, scales = "free",
               switch = "x") +
    geom_line() +
    labs(x = bquote(tau^2), y = "Density") +
    scale_x_continuous(sec.axis = sec_axis(trans = ~ ./so^2,
                                           name = bquote(tau^2/sigma[italic("o")]^2))) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(), strip.text.y = element_blank(),
          strip.background.x = element_blank(), strip.placement = "outside")

ggpubr::ggarrange(plottau, plotalpha, ncol = 2, align = "h")

## reestimate marginal posteriors under hierarchical model
normConstHierarch <- function(to, tr, so, sr, x, y) {
   ## TODO implement normalization
}
margPostThetarHierarch_ <- function(thetar, to, tr, so, sr, x, y,
                                    normConst = 1) {
    intFun <- function(tau2) {
        ## marginal posterior conditional on tau2
        dnorm(x = thetar,
              mean = (tr/sr^2 + to/(2*tau2 + so^2))/(1/sr^2 + 1/(2*tau2 + so^2)),
              sd = sqrt(1/(1/sr^2 + 1/(2*tau2 + so^2)))) *
            ## marginal posterior of tau2 (up to proportionality)
            exp(-0.5*(tr - to)^2/(so^2 + sr^2 + 2*tau2)) /
            sqrt(so^2 + sr^2 + 2*tau2) *
            dbeta(x = so^2/(2*tau2 + so^2), shape1 = x, shape = y) *
            2*so^2/(2*tau2 + so)^2
    }
    res <- try(integrate(f = intFun, lower = 0, upper = Inf)$value)
    if (class(res) == "try-error") {
        out <- NaN
    } else {
        out <- res / normConst
    }
    return(out)
}
margPostThetarHierarch <- Vectorize(FUN = margPostThetarHierarch_)
## thetarseq <- seq(0, 0.6, length.out = 1000)
## plot(thetarseq,
##      margPostThetarHierarch(thetar = thetarseq, to = to, tr = tr[1], so = so,
##                             sr = sr[1], x = 1, y = 1), type = "l")
## abline(v = 0.2)
@

% hi

\caption{Beta priors on power parameter $\alpha \sim \Be(x, y)$ (right) and
  corresponding priors on heterogeneity variance $\tau^2$ (left) that lead to
  matching marginal posteriors for the effect sizes $\theta$ and $\theta_{r}$.
  The variance of the original effect estimate
  $\sigma_{o} = \Sexpr{round(so, 2)}^{2}$ from the ``\Sexpr{ex}'' experiment is
  used for the transformation to the heterogeneity variance scale $\tau^{2}$.}
\label{fig:matchingpriors}
\end{figure}

Figure~\ref{fig:matchingpriors} illustrates several examples of matching priors
using the variance of the original effect estimate
% $\sigma_{o} = \Sexpr{round(so, 2)}^{2}$
from the ``\Sexpr{ex}'' experiment. % For instance, we see that a uniform prior on
% $\alpha$ implies a
% $f(\tau^{2}) \propto (2\sigma^{2}_{o})/(2\tau^{2} + \sigma^{2})^{2}$ for
    %     $\tau^{2}$.
We see that the uniform prior on $\alpha$ corresponds to a
$f(\tau^{2}) \propto \sigma^{2}_{o}/(2\tau^{2} + \sigma^{2}_{o})^{2}$ prior
which is similar to the ``uniform shrinkage'' prior
$f(\tau^{2}) \propto \sigma^{2}_{o}/(\tau^{2} + \sigma^{2}_{o})^{2}$
\citep{Daniels1999}. This prior has the highest density at $\tau^{2} = 0$,
however, it still gives mass to larger values of $\tau^{2}$. In contrast, the
$\alpha \sim \Be(2, 1)$ prior gives most mass to small values of $\tau^{2}$
relative to $\sigma^{2}$, while the $\alpha \sim \Be(2, 1)$ prior gives no
mass to small $\tau^{2}$ and has zero density at $\tau^{2} = 0$.

\section{Hypothesis testing}
\label{sec:hypothesis-testing}
Apart from estimation of $\theta$ and $\alpha$, one may also want to test
hypotheses. The standard Bayesian approach is to compute the Bayes factor
contrasting the likelihood of the data under two competing hypothesis
\citep{Jeffreys1961, Kass1995}, to quantify the strength of evidence for either
of them.


\subsection{Hypotheses about the effect size}
We may want to quantify the evidence for a non-zero effect size $\theta$ by
testing $H_{0} \colon \theta = 0$ to $H_{1} \colon \theta \neq 0$. This requires
specification of a prior distribution under $H_{1}$, a natural choice is to use
the normalized power prior based on the original data from~\eqref{eq:pp}. The
respective Bayes factor is then given by
\begin{align}
  % \BF_{01}^{\theta}
  \BF_{01}(\that_{r}\given x, y)% \given \alpha \sim f(\alpha \given H_{1}))
  &= \frac{f(\that_{r} \given H_{0})}{f(\that_{r} \given H_{1})}
    =  \frac{\Nor(\that_{r}; 0, \sigma^{2}_{r})}{\int_{0}^{1} \Nor(\that_{r}; \that_{o},
      % \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha) \, f(\alpha \given H_{1}) \, \text{d}\alpha}.
    \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha) \, \Be(\alpha; x, y) \, \text{d}\alpha}.
    % because of S-D ratio this is also given by
    % \frac{f(\theta = 0 \given \that_r, \that_o, \sigma_o, \sigma_r)}{f(\theta = 0)}
    % the ratio of marginal posterior to marginal prior evaluated at zero
  \label{eq:bf01}
\end{align}
A reasonable choice for the prior of $\alpha$ under $H_{1}$ is a uniform
$\alpha \sim \Be(1, 1)$ distribution. However, it is worth noting that fixing
$\alpha = 1$ leads to
\begin{align}
  % \BF_{01}^{\theta}
  \BF_{01}(\that_{r}\given \alpha = 1)
    =  \frac{\Nor(\that_{r}; 0, \sigma^{2}_{r})}{ \Nor(\that_{r}; \that_{o},
    \sigma^{2}_{o} + \sigma^{2}_{r})},
  \label{eq:bfr}
\end{align}
which is the \emph{replication Bayes factor} under normality
\citep{Verhagen2014, Ly2018, Pawel2020b}, that is, the Bayes factor contrasting
a point null hypothesis to the posterior distribution of the effect size based
on the original data (and in this case a uniform initial prior). A fixed
$\alpha = 1$ can also be seen as the limiting case of a beta prior with $y = 1$
and $x \to \infty$. The power prior version of the replication Bayes factor is
thus a generalization of the standard replication Bayes factor where the
original data are to some extent discounted.


\subsection{Hypotheses about the power parameter}
In order to quantify compatibility of original and replication study we may want
to test hypotheses regarding the power parameter $\alpha$ as it provides a link
between the studies. For example, we might want to test
$H_{\text{c}} \colon \alpha = 1$ (``compatible'') vs.
$H_{\text{d}} \colon \alpha < 1$ (``different''). One approach is to assign a
point prior $H_{\text{d}}\colon\alpha = 0$. This leads to the issue that for a
flat initial prior $f(\theta) \propto 1$, the power prior with $\alpha = 0$ is
not proper and so the resulting Bayes factor is only defined up to an arbitrary
constant. Instead of the flat prior, we may thus choose an uninformative but
proper initial prior, \eg the unit-information prior \citep{Kass1995b}
\begin{align*}
  \theta \sim \Nor(0, \kappa^{2})
\end{align*}
with $\kappa^{2}$ the variance from one (effective) observation. This leads to
the Bayes factor
\begin{align}
  \BF_{\text{dc}}(\that_{r} \given \kappa^{2})% \given \theta \sim \Nor(0, \kappa^{2}))
  &= \frac{f(\that_{r} \given H_{\text{d}})}{f(\that_{r}
    \given H_{\text{c}})}
    = \frac{\Nor(\that_{r};0, \sigma^{2}_{r} + \kappa^{2})}{\Nor(\that_{r}; s  \that_{o}, \sigma^{2}_{r} + s  \sigma^{2}_{o})}
    \label{eq:bfalpha}
\end{align}
with shrinkage factor
$s = (\kappa^{2}/\sigma^{2}_{o}) / \{1 + (\kappa^{2}/\sigma^{2}_{o})\}$.

An alternative approach that avoids the specification of a proper initial prior
for $\theta$ is to assign priors to $\alpha$ under $H_{\text{d}}$ and
$H_{\text{c}}$. A suitable class of priors are
$H_{\text{d}}\colon \alpha \sim \Be(1, y)$ and
$H_{\text{c}}\colon \alpha \sim \Be(x, 1)$ with $x, y > 1$. Two examples with
$x = 2$ and $y = 2$ are shown in Figure~\ref{fig:matchingpriors}. These priors
have the highest density at $\alpha = 0$, respectively, $\alpha = 1$ and they
are monotonically decreasing, respectively, increasing.
%     Moreover, the approach
% also allows to use flat initial priors for the effect size. The resulting Bayes
% factor is given by
% \begin{align*}
%   \BF_{\text{dc}}(\that_{r}; x_{\text{c}}, y_{\text{d}})% \given \theta \sim \Nor(0, \kappa^{2}))
%   &=  \frac{\int_{0}^{1}\Nor(\that_{r};\that_{o}, \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha) \,
%     \Be(\alpha; 1, y_{\text{d}}) \, \text{d}\alpha}{\int_{0}^{1}\Nor(\that_{r};\that_{r}, \sigma^{2}_{r}
%     + \sigma^{2}_{o}/\alpha) \, \Be(\alpha; x_{\text{c}}, 1) \, \text{d}\alpha}.
% \end{align*}
Finally, a compromise between the two approaches is to contrast the composite
hypothesis $H_{\text{d}}\colon \alpha \sim \Be(1, y_{\text{d}})$ to the simple
hypothesis $H_{\text{c}} \colon \alpha = 1$, as also under this approach no
proper initial prior has to be specified for the effect size $\theta$. The
resulting Bayes factor is then given by
\begin{align}
  \label{eq:bfdcrandom}
  \BF_{\text{dc}}(\that_{r}\given y)
  &=  \frac{\int_{0}^{1}\Nor(\that_{r};\that_{o}, \sigma^{2}_{r} + \sigma^{2}_{o}/\alpha) \,
    \Be(\alpha; 1, y) \, \text{d}\alpha}{\Nor(\that_{r};\that_{o}, \sigma^{2}_{r}
    + \sigma^{2}_{o})}.
\end{align}
The parameter $y$ determines how much mass small values of $\alpha$ receive
under $H_{\text{d}}$. The simple hypothesis $H_{\text{d}} \colon \alpha = 0$ can
be seen as a limiting case when $y \to \infty$.

\subsection{Example ``\Sexpr{ex}'' (continued)}
Table~\ref{tab:hypothesis} displays the results of the proposed hypothesis tests
applied to the three replications of the experiment ``\Sexpr{ex}''. We see from
the Bayes factors contrasting $H_{0}$ to $H_{1}$ that the data indicate absence
of evidence for either hypothesis in the first replication, but decisive
evidence for $H_{1}$ in the second and third replication. In all three cases,
the Bayes factors are very close to the standard replication Bayes factors
obtained from setting $\alpha = 1$.
\begin{table}[!htb]
  \centering
  \caption{Hypothesis tests for replications of experiment ``\Sexpr{ex}'' with
    original standardized mean difference effect estimate
    $\that_{o} = \Sexpr{round(to, 2)}$ and standard error
    $\sigma_{o} = \Sexpr{round(so, 2)}$. Shown are replication effect estimates
    $\that_{r}$ with standard errors $\sigma_{r}$, Bayes factors contrasting
    $H_{0}\colon \theta = 0$ to $H_{1} \colon \theta \neq 0$ for different
    priors for $\alpha$ under $H_{1}$, and Bayes factors contrasting
    $H_{\text{d}}\colon \alpha < 1$ to $H_{\text{c}}\colon \alpha = 1$.\\}
  \label{tab:hypothesis}

<< "bf-testing", results = "asis" >>=
## compute BFs for effect sizes and power parameter
k <- sqrt(2)
x <- 1
y <- 1
xc <- 2
yd <- 2
bfDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    ## compute suite of BFs for power prior models
    bf01 <- bfPPtheta(tr = tr[i], sr = sr[i], to = to, so = so, x = x, y = y)
    bfr <- bfPPtheta(tr = tr[i], sr = sr[i], to = to, so = so, alpha = 1)
    bfdc <- bfPPalpha(tr = tr[i], sr = sr[i], to = to, so = so, uv = k^2)

    ## compute BFdc with random alpha
    ## fHd <- integrate(f = function(alpha) {
    ##     dnorm(x = tr[i], mean = to, sd = sqrt(sr[i]^2 + so^2/alpha)) *
    ##         dbeta(x = alpha, shape1 = 1, shape2 = yd)
    ## }, lower = 0, upper = 1)$value
    ## ## fHc <- integrate(f = function(alpha) {
    ## ##     dnorm(x = tr[i], mean = to, sd = sqrt(sr[i]^2 + so^2/alpha)) *
    ## ##         dbeta(x = alpha, shape1 = xc, shape2 = 1)
    ## ## }, lower = 0, upper = 1)$value
    ## fHc <- dnorm(x = tr[i], mean = to, sd = sqrt(sr[i]^2 + so^2))
    ## bfdcRandom <- fHd/fHc
    bfdcRandom <- bfPPalpha(tr = tr[i], sr = sr[i], to = to, so = so, y = yd)

    out <- data.frame(number = rnumber[i], tr = tr[i], sr = sr[i], bf = bf01,
                      bfr = bfr, bfdc = bfdc, bfdcRandom = bfdcRandom)
    return(out)
}))

## create nice table
library(xtable)
library(dplyr)
dfTab <- bfDF %>%
    mutate(bf = formatBF(bf),
           bfr = formatBF(bfr),
           bfdc = formatBF(bfdc),
           bfdcRandom = formatBF(bfdcRandom),
           tr = round(tr, 2),
           sr = round(sr, 2),
           number = as.integer(number)) %>%
    arrange(tr)
xtab <- xtable(dfTab)
## colnames(xtab) <- c("$\\hat{\\theta}_r$",
##                     "$\\sigma_r$",
##                     "$\\BF_{01}(\\hat{\\theta}_r \\given \\alpha \\sim \\Be(1, 1))$",
##                     "$\\BF_{01}(\\hat{\\theta}_r \\given \\alpha = 1)$",
##                     "$\\BF_{\\text{dc}}(\\hat{\\theta}_r \\given \\theta \\sim \\Nor(0, 2))$")
colnames(xtab) <- c("",
                    "$\\hat{\\theta}_r$",
                    "$\\sigma_r$",
                    paste0("$\\BF_{01}(\\hat{\\theta}_r \\given x =", x, ", y =", y, ")$"),
                    "$\\BF_{01}(\\hat{\\theta}_r \\given \\alpha = 1)$",
                    paste0("$\\BF_{\\text{dc}}(\\hat{\\theta}_r \\given \\kappa^2 =",
                           k^2, ")$"),
                    ## paste0("$\\BF_{\\text{dc}}(\\hat{\\theta}_r \\given x =", xc,
                    ##        ", y = ", yd, ")$")
                    paste0("$\\BF_{\\text{dc}}(\\hat{\\theta}_r \\given y = ",
                           yd, ")$"))
align(xtab) <- rep("c", length(colnames(xtab)) + 1)
print(xtab, floating = FALSE, include.rownames = FALSE,
      sanitize.text.function = function(x){x}, booktabs = TRUE)
@
\end{table}

In order to compute the Bayes factor for testing simple $H_{\text{d}}$ vs.
simple $H_{\text{c}}$ we need to specify a unit variance for the
unit-information prior. A crude approximation for the variance of a standardized
mean difference effect estimate is given by $\Var(\that_i) = 4/n_{i}$ with
$n_{i}$ the total sample size of the study, and assuming equal sample size in
both groups \citep[p. 5]{Hedges2021}. We may thus set the variance of the
unit-information prior to $\kappa^{2} = 2$ since at least one observation from
each group is required to estimate a standardized mean difference (assuming the
variance is known). Based on this choice, the data provide substantial,
respectively strong evidence for $H_{\text{c}}$ in the first and second
replication study, while they indicate strong evidence for $H_{\text{d}}$ in the
third replication study. Looking at the Bayes factor which instead contrasts the
composite $H_{\text{d}}\colon \alpha \sim \Be(1, \Sexpr{yd})$, it indicates
absence of evidence for either hypothesis in the first and second replication,
but in the third replication even stronger evidence for $H_{\text{d}}$ than
under the simple approach.

To conclude, our analysis suggests that only the second replication was
successful in the sense that it is compatible with the original study while also
providing evidence against a null effect. The first replication is compatible
but does not provide any evidence for a non-zero effect, whereas the second
replication provides much evidence for an effect but is incompatible with the
original study.

\subsection{Asymptotics}
It is of interest to investigate the asymptotic behavior of the proposed Bayes
factors. For instance, we may want to understand what happens when the sample
size of the replication study $n_{r}$ becomes larger. Assume that $\that_{r}$ is
a consistent estimator of the true underlying effect size $\tilde{\theta}$, and
that the standard error is inversely proportional to the square root of the
sample size $\sigma_{r} = \kappa/\sqrt{n_{r}}$ with $\kappa^{2}$ some unit
variance. As the replication sample size goes to infinity ($n_{r} \to \infty$),
the estimate will converge in probability to the true effect size, and the
standard error will go to zero.

<< "bf-bound" >>=
## compute bound on the Bayes factor
k <- sqrt(2)
g <- k^2/so^2
s <- g/(1 + g)
trueESmin <- to ## minimized for true effect size = original effect estimate
bfBound <- dnorm(x = trueESmin, mean = 0, sd = k)/
    dnorm(x = trueESmin, mean = s*to, sd = sqrt(s)*so)

## ## bf with sr = 0 as a function of true effect size
## trueES <- seq(to*0.9, to*1.1, length.out = 1000)
## bfseq <- dnorm(x = trueES, mean = 0, sd = k)/
##     dnorm(x = trueES, mean = s*to, sd = sqrt(s)*so)
## plot(trueES, bfseq, type = "l", log = "y", xlab = bquote(tilde(theta)),
##      ylab = bquote(BF["dc"]^"*"))
## abline(v = trueESmin, lty = 2)
## abline(h = dnorm(x = trueESmin, mean = 0, sd = k)/
##            dnorm(x = trueESmin, mean = s*to, sd = sqrt(s)*so), lty = 2)
@

%     Assuming that the original estimate was not zero ($\that_{o} \neq 0$), t
Assuming that the prior for $\alpha$ under $H_{1}$ has mass for $\alpha > 0$,
the Bayes factor~\eqref{eq:bf01} % with $\alpha = 1$ (the replication Bayes
% factor)
is information consistent, meaning that it will increasingly favor the
correct hypothesis as the replication data accumulate. In contrast, the Bayes factors~\eqref{eq:bfalpha} and~\eqref{eq:bfdcrandom} do not grow
unboundedly but converge to constants
\begin{align}
  \label{eq:boundsimple}
  % \lim_{n_{r} \to \infty} \BF_{\text{dc}} (\that_{r}\given \theta \sim \Nor(0, \kappa^{2}))
  \BF_{\text{dc}}^{*}(\kappa^{2})
  &= % \frac{\Nor(\that_{r};0, \kappa^{2})}{\Nor(\that_{r}; s  \that_{o},
    % s  \sigma^{2}_{o})}
    \sqrt{s  \sigma^{2}_{o}/\kappa^{2}} \, \exp\left[
    -\frac{1}{2} \, \left\{\frac{\tilde{\theta}^{2}}{\kappa^{2}} -
    \frac{(\tilde{\theta} - \that_{o})^{2}}{s  \sigma^{2}_{o}}\right\}\right]
\end{align}
and
\begin{align*}
  \BF_{\text{dc}}^{*}(y)
  &= \frac{\int_{0}^{1} \Nor(\tilde{\theta}; \that_{o}, \sigma^{2}_{o}/\alpha)\,
    \Be(\alpha; 1, y) \, \text{d}\alpha}{\Nor(\tilde{\theta}; \that_{o}, \sigma^{2}_{o})}.
\end{align*}
The amount of evidence one can find for either hypothesis thus depends on the
original effect estimate $\that_{o}$, standard error $\sigma_{o}$, and the true
effect size $\tilde{\theta}$. For instance, in the example from before we have
an original effect estimate $\that_{o} = \Sexpr{round(to, 2)}$ and standard
error $\sigma_{o} = \Sexpr{round(so, 2)}$. The bound~\eqref{eq:boundsimple} is
minimized for a true effect size of
$ \tilde{\theta} = (\that_{o})/\{1 - (s \sigma^{2}_{o})/\kappa^{2}\} = \Sexpr{round(trueMin, 2)}$,
so the most extreme level we can obtain is
$\BF_{\text{dc}}^{*} = \Sexpr{formatBF(bfBound)}$. Even in an infinitely precise
replication study, we cannot find more evidence for $H_{\text{c}}$.


\subsection{Connection to hypothesis testing in hierarchical models}

As with parameter estimation, it is also of interest to know whether there is a
correspondence between hypothesis tests in the power prior and the hierarchical
modeling frameworks. Concerning the % replication Bayes factor under normality
% from~\eqref{eq:bfr} it is straightforward to show that it matches with the Bayes
% factor contrasting
% \begin{align*}
%   &H_{0}\colon \theta_{*} = 0, \tau^{2} = 0&
%   &\text{to}&
%   &H_{1} \colon \theta_{*} \given \tau^{2} \sim \Nor(\that_{o}, \sigma^{2}_{o} + \tau^{2}),
%     \tau^{2} = 0&
% \end{align*}
generalized replication Bayes factor
from~\eqref{eq:bf01} testing $H_{0} \colon \theta = 0$ vs.
$H_{1} \colon \theta \neq 0$ %\sim \Nor(\that_{o}, \sigma^{2}_{o}/\alpha)$,
it is straightforward to show that it matches with the Bayes factor contrasting
\begin{align*}
  &H_{0}\colon \theta_{*} = 0& &\text{to}&
  &H_{1} \colon \theta_{*} \given \tau^{2} \sim \Nor(\that_{o}, \sigma^{2}_{o} + \tau^{2})& \\
  &\phantom{H_{0}\colon} \tau^{2} = 0& &&
  &\phantom{H_{0}\colon} f(\tau^{2}) = \Be\left\{\alpha = \sigma^{2}_{o}/(\sigma^{2}_{o} +
    2\tau^{2}), x, y\right\}
    (2\sigma^{2}_{o})/(2\tau^{2} + \sigma^{2})^{2}&
    %     f(\tau^{2}) = f\{\tau^{2} = (1/\alpha - 1)\, (\sigma^{2}_{o}/2)\}\{\sigma^{2}_{o}/(2\alpha^{2})\}&
\end{align*}
in the hierachical framework. % Under $H_{1}$ one may also assign a prior
% distribution to $\tau^{2}$ which must satisfy the
% conditions~\eqref{eq:matchCond} as for the matching posteriors.
The Bayes factor thus compares the plausibility of the replication data under
the hypothesis $H_{0}$ that the global effect size $\theta_{*}$ is zero and that
there is no effect size heterogeneity, relative to the plausibility of the data
under the hypothesis $H_{1}$ that $\theta_{*}$ follows the posterior based on
the original data and an initial flat prior for $\theta_{*}$. Setting the
heterogenetiy variance $\tau^2 = 0$ under $H_1$ produces the standard
replication Bayes factor under normality from~\eqref{eq:bfr}.

The Bayes factor~\eqref{eq:bfalpha} testing $H_{\text{c}}\colon \alpha = 1$ to
$H_{\text{d}}\colon \alpha = 0$ can be obtained in the hierarchical framework by
contrasting
\begin{align*}
  &H_{\text{d}}\colon \theta_{*} \sim \Nor(0, \kappa^{2}), \tau^{2} = 0&
  &\text{to}&
  &H_{\text{c}} \colon \theta_{*} \sim \Nor(s\,\that_{o}, s\,\sigma^{2}_{o}), \tau^{2} = 0&
\end{align*}
with $s = (\kappa^{2}/\sigma^{2}_{o})/\{1 + (\kappa^{2}/\sigma^{2}_{o})\}$.
The Bayes factor hence compares the plausibility of the replication data under
the initial unit-information prior relative to plausibility of the replication
data under the unit-information prior updated by the original data, assuming no
heterogeneity under either hypothesis. Finally, the Bayes
factor~\eqref{eq:bfdcrandom} testing $H_{\text{c}}\colon \alpha = 1$ vs.
$H_{\text{d}}\colon \alpha \sim \Be(1, y)$ corresponds to testing
\begin{align*}
  &H_{\text{d}}\colon \tau^{2} = 0&
  &\text{to}&
  &H_{\text{c}} \colon f(\tau^{2}) = \Be\left\{\alpha = \sigma^{2}_{o}/(\sigma^{2}_{o} +
    2\tau^{2}), 1, y\right\}
    (2\sigma^{2}_{o})/(2\tau^{2} + \sigma^{2})^{2}
  % f\{\tau^{2} = (1/\alpha - 1)\, (\sigma^{2}_{o}/2)\}\{\sigma^{2}_{o}/(2\alpha^{2})\} &
\end{align*}
in the hierarchical framework.


\subsection{Design}

Assume now that the replication study has not yet been conducted and we want to
determine its sample size. In the case of the replication Bayes factor under
normality~\eqref{eq:bfr}, \citet{Pawel2020b} derived the probability of
replication success in closed form under $H_{0}$ and $H_{1}$. Based on their
result, standard Bayesian design analysis \citep{Weiss1997, DeSantis2004,
  Schoenbrodt2017} can be conducted to determine the appropriate replication
sample size. For the generalized replication Bayes factor~\eqref{eq:bf01},
numerical integration or simulation is required to compute the probability of
replication success as the marginal likelihood is not available in closed form
under $H_{1}$.

It is also possible to derive the probability of replication success
analytically for the simple-simple power parameter Bayes
factor~\eqref{eq:bfalpha}. With some algebra, one can show that
$\BF_{\text{dc}} \leq \gamma$ is equivalent to
% \begin{align*}
%   2\log\gamma - \log\left(\frac{\sigma^{2}_{r} + s  \sigma^{2}_{o}}{
%   \sigma^{2}_{r} + \kappa^{2}}\right)
%   &\geq \frac{(\that_{r} - s  \that_{o})^{2}}{
%   \sigma^{2}_{r} + s  \sigma^{2}_{o}} - \frac{\that_{r}^{2}}{\sigma^{2}_{r} +
%   \kappa^{2}} \\
%   &= \frac{\kappa^{2} - s  \sigma^{2}_{o}}{(\sigma^{2}_{r} + \kappa^{2})
%     (\sigma^{2}_{r} + s  \sigma^{2}_{o})} \left(\that_{r} -
%     \frac{s \that_{o} \, (\sigma^{2}_{r} + \kappa^{2})}{\kappa^{2} -
%     s  \sigma^{2}_{o}}\right)^{2}
% \end{align*}
% which is equivalent to
\begin{align}
  \left(\that_{r} -
  \frac{s \that_{o} (\sigma^{2}_{r} + \kappa^{2})}{\kappa^{2} -
  s  \sigma^{2}_{o}}\right)^{2}
  \leq X =&
    \frac{(\sigma^{2}_{r} + \kappa^{2})(\sigma^{2}_{r} +
    s  \sigma^{2}_{o})}{\kappa^{2} - s  \sigma^{2}_{o}}
    \left\{\log\gamma^{2}- \log\left(\frac{\sigma^{2}_{r} + s  \sigma^{2}_{o}}{
            \sigma^{2}_{r} + \kappa^{2}}\right) - \frac{s^{2}  \that^{2}_{o}}{s  \sigma^{2}_{o} - \kappa^{2}}\right\}
    \label{eq:RScond}
\end{align}
for $\kappa^{2} > s  \sigma^{2}_{o}$. Denote by $m_{i}$ and $v_{i}$ the
mean and variance of $\that_{r}$ under hypothesis $i \in \{d, c\}$. The left
hand side of~\eqref{eq:RScond} then follows scaled non-central chi-squared
distribution under both hypotheses. The probability of replication success is
hence given by
\begin{align}
  \Pr(\BF_{\text{dc}} \leq \gamma \given H_{i})
  &= \Pr\left(\chi^{2}_{1,\lambda_{i}} \leq X/v_{i} \right)
    \label{eq:PRS}
\end{align}
with non-centrality parameter
\begin{align*}
  \lambda_{i}
  = \left(m_{i} - \frac{s \that_{o}  (\sigma^{2}_{r} + \kappa^{2})}{\kappa^{2}
  - s  \sigma^{2}_{o}}\right)^{2} \big / v_{i}.
\end{align*}

To determine the replication sample size, we can now use~\eqref{eq:PRS} to
compute the probability of replication success at a desired level $\gamma$ over
a grid of replication standard errors $\sigma_{r}$, and under either hypothesis
$H_{\text{d}}$ and $H_{\text{c}}$. The appropriate standard error is then chosen
so that the probability for finding correct evidence is sufficiently high under
the respective hypothesis, and sufficiently low under the wrong hypothesis.
Subsequently, the standard error $\sigma_{r}$ needs to be translated into a
sample size, \eg for standardized mean differences via the aforementioned
approximation $n_{r} \approx 4/\sigma^{2}_{r}$.


\begin{figure}[!htb]
<< "design", fig.height = 4.5 >>=
## probability of relpication success
powerFun <- function(sr, to, so, k, level, mi, vi) {
    s <- k^2/so^2 / (1 + k^2/so^2)
    X <- (sr^2 + k^2) * (sr^2 + s * so^2) / (k^2 - s * so^2) *
        (2 * log(level) - log((sr^2 + s * so^2) / (sr^2 + k^2)) -
         s^2*to^2/(s*so^2 - k^2))
    lambdai <- (mi - s * to * (sr^2 + k^2) / (k^2 - s * so^2))^2/vi
    p <- stats::pchisq(q = X/vi, df = 1, ncp = lambdai, lower.tail = TRUE)
    return(p)
}

## compute proability of replication success for a grid of replication
## standard errors
cSeq <- exp(seq(log(1/12), log(12), length.out = 1000))
cbks <- c(1/10, 1/3, 1, 3, 10)

level <- 1/10
plotDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    to <- tr[i]
    so <- sr[i]
    srSeq <- so / sqrt(cSeq)
    ## mean and variance under Hd and Hc
    md <- 0
    vd <- srSeq^2 + k^2
    s <- k^2/so^2 / (1 + k^2/so^2)
    mc <- s*to
    vc <- srSeq^2 + s*so^2
    ## power to achieve BF < level
    p1Hd <- powerFun(sr = srSeq, to = to, so = so, k = k, level = level,
                     mi = md, vi = vd)
    p1Hc <- powerFun(sr = srSeq, to = to, so = so, k = k, level = level,
                     mi = mc, vi = vc)
    outDF1 <- rbind(data.frame(p = p1Hd, level = level, type = "italic(H['d'])",
                               sr = srSeq, c = cSeq, to = to, so = so,
                               direction = "<="),
                    data.frame(p = p1Hc, level = level, type = "italic(H['c'])",
                               sr = srSeq, c = cSeq, to = to, so = so,
                               direction = "<="))
    ## power to achieve BF > 1/level
    p2Hd <- 1 - powerFun(sr = srSeq, to = to, so = so, k = k, level = 1/level,
                         mi = md, vi = vd)
    p2Hc <- 1 - powerFun(sr = srSeq, to = to, so = so, k = k, level = 1/level,
                         mi = mc, vi = vc)
    outDF2 <- rbind(data.frame(p = p2Hd, level = 1/level, type = "italic(H['d'])",
                               sr = srSeq, c = cSeq, to = to, so = so,
                               direction = ">="),
                    data.frame(p = p2Hc, level = 1/level, type = "italic(H['c'])",
                               sr = srSeq, c = cSeq, to = to, so = so,
                               direction = ">="))
    outDF <- rbind(outDF1, outDF2)
    outDF$yFacetLab <- paste0("'Pr(BF'['dc']", outDF$direction,
                              formatBF(outDF$level),
                              "~ '|' ~ italic(H['i']) *", "')'")
    outDF$xFacetLab <- paste0("{hat(theta)[italic(o)] ==",
                              round(outDF$to, 2),
                              "}*', '*sigma[italic(o)] == ",
                              round(outDF$so, 2))
    return(outDF)
}))
## do.call("rbind", lapply(X = seq(1, length(to)), FUN = function(i) {
##     to <- to[i]
##     so <- to[i]
##     ## mean and variance under Hd and Hc
##     md <- 0
##     vd <- srSeq^2 + k^2
##     s <- k^2/so^2 / (1 + k^2/so^2)
##     mc <- s*to
##     vc <- srSeq^2 + s*so^2
##     ## power to achieve BF < level
##     p1Hd <- powerFun(sr = srSeq, to = to, so = so, k = k, level = level,
##                      mi = md, vi = vd)
##     p1Hc <- powerFun(sr = srSeq, to = to, so = so, k = k, level = level,
##                      mi = mc, vi = vc)
##     outDF1 <- rbind(data.frame(p = p1Hd, level = level, type = "italic(H['d'])",
##                                sr = srSeq, c = cSeq, to = to, so = so,
##                                direction = "<="),
##                     data.frame(p = p1Hc, level = level, type = "italic(H['c'])",
##                                sr = srSeq, c = cSeq, to = to, so = so,
##                                direction = "<="))
##     ## power to achieve BF > 1/level
##     p2Hd <- 1 - powerFun(sr = srSeq, to = to, so = so, k = k, level = 1/level,
##                          mi = md, vi = vd)
##     p2Hc <- 1 - powerFun(sr = srSeq, to = to, so = so, k = k, level = 1/level,
##                          mi = mc, vi = vc)
##     outDF2 <- rbind(data.frame(p = p2Hd, level = 1/level, type = "italic(H['d'])",
##                                sr = srSeq, c = cSeq, to = to, so = so,
##                                direction = ">="),
##                     data.frame(p = p2Hc, level = 1/level, type = "italic(H['c'])",
##                                sr = srSeq, c = cSeq, to = to, so = so,
##                                direction = ">="))
##     outDF <- rbind(outDF1, outDF2)
##     outDF$yFacetLab <- paste0("'Pr(BF'['dc']", outDF$direction,
##                               formatBF(outDF$level),
##                               "~ '|' ~ italic(H['i']) *", "')'")
##     outDF$xFacetLab <- paste0("{hat(theta)[italic(o)] ==",
##                               round(outDF$to, 2),
##                               "}*', '*sigma[italic(o)] == ",
##                               round(outDF$so, 2))
##     return(outDF)
## }))

pow <- 0.8
ssDF <- do.call("rbind", lapply(X = seq(1, length(tr)), FUN = function(i) {
    to <- tr[i]
    so <- sr[i]
    ## standard error to achieve P(BF < level | Hc, sr) = 0.8
    rootFunHc <- function(c) {
        sr <- so/sqrt(c)
        mc <- s*to
        vc <- sr^2 + s*so^2
        powerFun(sr = sr, to = to, so = so, k = k, level = level,
                 mi = mc, vi = vc) - pow
    }
    resHd <- try(uniroot(f = rootFunHc, interval = c(1/100, 100))$root)
    if (class(resHd) == "try-error") {
        srHc <- NaN
    } else {
        srHc <- so/sqrt(resHd)
    }
    ## standard error to achieve P(BF > 1/level | Hd, sr) = 0.8
    rootFunHd <- function(c) {
        sr <- so/sqrt(c)
        md <- 0
        vd <- sr^2 + k^2
        (1 - powerFun(sr = sr, to = to, so = so, k = k, level = 1/level,
                      mi = md, vi = vd)) - pow
    }
    resHd <- try(uniroot(f = rootFunHd, interval = c(1/100, 100))$root)
    if (class(resHd) == "try-error") {
        srHd <- NaN
    } else {
        srHd <- so/sqrt(resHd)
    }
    outDF <- rbind(data.frame(level = 1/level, type = "italic(H['d'])",
                              sr = srHd, c = so^2/srHd^2, to = to, so = so,
                              direction = ">=", power = pow),
                   data.frame(level = level, type = "italic(H['c'])",
                              sr = srHc, c = so^2/srHc^2, to = to, so = so,
                              direction = "<=", power = pow))
    outDF$yFacetLab <- paste0("'Pr(BF'['dc']", outDF$direction,
                              formatBF(outDF$level),
                              "~ '|' ~ italic(H['i']) *", "')'")
    outDF$xFacetLab <- paste0("{hat(theta)[italic(o)] ==",
                              round(outDF$to, 2),
                              "}*', '*sigma[italic(o)] == ",
                              round(outDF$so, 2))
    return(outDF)
}))

powbks <- seq(0, 1, 0.2)
ggplot(data = plotDF, aes(x = c, y = p, color = type)) +
    facet_grid(yFacetLab ~ xFacetLab, labeller = label_parsed,
               switch = "y") +
    geom_hline(yintercept = pow, lty = 2, alpha = 0.1) +
    geom_line(alpha = 0.9) +
    geom_point(data = ssDF, aes(x = c, y = power), size = 0.8,
               show.legend = FALSE) +
    geom_segment(data = ssDF, aes(x = c, xend = c, y = power, yend = 0),
                 alpha = 0.3, arrow = arrow(length = unit(0.15, "cm")),
                 show.legend = FALSE, size = 0.5) +
    labs(x = bquote("Relative variance" ~ sigma[italic(o)]^2/sigma[italic(r)]^2  %~~%
                        italic(n[r]) / italic(n[o])),
         y = NULL, color = NULL) +
    scale_y_continuous(breaks = powbks, labels = scales::percent,
                       limits = c(0, 1)) +
    scale_color_brewer(palette = "Dark2", labels = scales::parse_format()) +
    scale_x_log10(breaks = cbks, labels = formatBF(cbks)) +
    theme_bw() +
    theme(panel.grid.minor = element_blank(),
          strip.background.y = element_blank(), strip.placement = "outside")

## check that quadratic forms correctly combined
## (tr - to*s)^2/(sr^2 + s*so^2) - tr^2/(sr^2 + k^2)
## (k^2 - s*so^2)/((sr^2 + k^2)*(sr^2 + s*so^2))*
##     (tr - to*s*(sr^2 + k^2)/(k^2 - s*so^2))^2 + to^2*s^2/(s*so^2 - k^2)
@
\caption{Probability of replication success as a function of relative variance
  for the three replications of experiment ``\Sexpr{ex}'' regarded as original
  study. Relative sample size that correspond to a probability of
  \Sexpr{round(100*pow, 2)}\% under the respective hypothesis are indicated by
  arrows.}
\label{fig:ssd}
\end{figure}

\subsection{Example ``\Sexpr{ex}'' (continued)}

Figure~\ref{fig:ssd} illustrates Bayesian design analysis based on the power
parameter Bayes factor for the three replication studies from the experiment
``\Sexpr{ex}'' which are now each regarded as original studies. Shown is the
probability of replication success as a function of the relative sample size.
The curves look more or less similar for all three studies. We see from the
lower panels that the probability for finding strong evidence for $H_{\text{c}}$
is not much affected by the sample size of the replication study staying at
almost zero under $H_{\text{c}}$, while under $H_{\text{d}}$ it increases from
about 75\% to about 90\%. In contrast, the top panels show that the probability
for finding strong evidence for $H_{c}$ rapidly increases under $H_{\text{c}}$
and seems to level off at an asymptote. Under $H_{\text{d}}$ the probability
stays below 10\% across the whole range.

The plots also display the required replication sample size to obtain strong
evidence with probability of $\Sexpr{round(100*pow, 2)}\%$ under the correct
hypothesis. We see that original studies with smaller standard errors require
smaller replication sample sizes to achieve the same probability of replication
success. Under $H_{\text{c}}$ the required sample sizes are larger than under
$H_{\text{d}}$. However, while the probability of misleading evidence under
$H_{\text{c}}$ seems to be well controlled under the determined sample size,
under $H_{\text{d}}$ it stays roughly 5\% for all three studies, and even for
very large replication sample sizes.

For all three studies choosing the sample size based on finding strong evidence
for $H_{\text{c}}$ assuming $H_{\text{c}}$ is true also guarantees appropriate
error probabilities for finding strong evidence for $H_{\text{d}}$. At the same
time, it seems that the probability for finding misleading evidence for
$H_{\text{c}}$ cannot be reduced below around 5\% which might undesirably high
for certain applications.


\section{Discussion}
We showed how the power prior framework can be used for design and analysis of
replication studies. The approach supplies analysts with a suite of methods for
assessing effect sizes and study compatibility. We also show how the approach is
connected to hierarchical modeling, and gave the conditions under which
posterior distributions and hypothesis tests can be mapped from normal power
prior models to the normal-normal hierarchical models. This connection helps
explaining why even with two highly precise studies we were unable to make
conclusive posterior inferences about the power parameter. Just as it is
difficult to learn about a heterogeneity variance from two studies, it seems
difficult to do learn about the power parameter from two studies alone. Failed
replication efforts (in terms of null hypothesis testing) have led many to argue
that researchers should shift their focus to effect size comparison. Our results
show that in order to obtain conclusive evidence for effect size compatibility,
highly precise effect estimates are required, regardless whether power prior or
hierarchical modeling frameworks are used. % Obtaining high enough estimation
% accuracy is likely is more resource intensive than obtaining conclusive evidence
% for testing a null hypothesis. \dots
%     , often more difficult than to find evidence
% against a null hypothesis (especially when data are noisy and when the samples
% size is small).

% \section*{Software and data}
% The data were taken from \dots. All analyses were conducted in the R programming
% language version \Sexpr{paste(version$major, version$minor, sep = ".")}
% \citep{R}. The code to reproduce this manuscript is available at \dots All
% methods are implemented in the R package \texttt{X} which is available at
% \dots

% \section*{Acknowledgments}
% We thank


% Appendix
% ------------------------------------------------------------------------------
% \begin{appendices}


% \end{appendices}


% Bibliography
% % ------------------------------------------------------------------------------
\bibliographystyle{apalikedoiurl}
\bibliography{bibliography}


% \end{multicols}

\end{document}
